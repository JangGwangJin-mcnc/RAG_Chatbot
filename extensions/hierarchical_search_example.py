# ë¶€ëª¨-ìì‹ ì „ëµ ì‚¬ìš© ì˜ˆì‹œ
import streamlit as st
import os
from extensions.hierarchical_search import ParentChildSearchStrategy

# SafeSentenceTransformerEmbeddings í´ë˜ìŠ¤ ì •ì˜ (torch.load ì·¨ì•½ì  ë°©ì§€)
class SafeSentenceTransformerEmbeddings:
    def __init__(self, model_name: str = 'sentence-transformers/all-mpnet-base-v2', device: str = 'cpu'):
        self.model_name = model_name
        self.device = device
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ (safetensors ì§ì ‘ ì‚¬ìš©)"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ safetensors ê°•ì œ ì‚¬ìš©
            os.environ['SAFETENSORS_FAST_GPU'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '0'
            os.environ['TORCH_WEIGHTS_ONLY'] = '1'
            os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
            os.environ['TRANSFORMERS_USE_SAFETENSORS'] = '1'
            os.environ['TORCH_WARN_ON_LOAD'] = '0'
            os.environ['TORCH_LOAD_WARN_ONLY'] = '0'
            os.environ['TRANSFORMERS_SAFE_SERIALIZATION'] = '1'
            os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
            
            # transformersì™€ safetensorsë¥¼ ì§ì ‘ ì‚¬ìš©
            from transformers import AutoTokenizer, AutoModel
            import torch
            import safetensors
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                use_safetensors=True
            )
            
            # ëª¨ë¸ ë¡œë“œ (safetensors ê°•ì œ ì‚¬ìš©)
            self.model = AutoModel.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                use_safetensors=True,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True
            )
            
            self.model.to(self.device)
            self.model.eval()
            
        except Exception as e:
            raise Exception(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def embed_documents(self, texts):
        """ë¬¸ì„œ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            embeddings = []
            for text in texts:
                # í† í¬ë‚˜ì´ì§•
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    max_length=512,
                    truncation=True,
                    padding=True
                )
                
                # GPUë¡œ ì´ë™
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # ì„ë² ë”© ìƒì„±
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    # ë§ˆì§€ë§‰ hidden stateì˜ í‰ê· ì„ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
                    embedding = outputs.last_hidden_state.mean(dim=1)
                    embeddings.append(embedding.cpu().numpy().flatten().tolist())
            
            return embeddings
            
        except Exception as e:
            raise Exception(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
    
    def embed_query(self, text: str):
        """ì¿¼ë¦¬ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                max_length=512,
                truncation=True,
                padding=True
            )
            
            # GPUë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì„ë² ë”© ìƒì„±
            with torch.no_grad():
                outputs = self.model(**inputs)
                # ë§ˆì§€ë§‰ hidden stateì˜ í‰ê· ì„ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
                embedding = outputs.last_hidden_state.mean(dim=1)
                return embedding.cpu().numpy().flatten().tolist()
                
        except Exception as e:
            raise Exception(f"ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")

def hierarchical_search_example():
    """ë¶€ëª¨-ìì‹ ì „ëµ ì‚¬ìš© ì˜ˆì‹œ"""
    
    st.header("ğŸ” ë¶€ëª¨-ìì‹ ì „ëµ ê²€ìƒ‰ ì˜ˆì‹œ")
    
    # 1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    st.subheader("1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”")
    try:
        # SafeSentenceTransformerEmbeddings ì‚¬ìš© (torch.load ì·¨ì•½ì  ë°©ì§€)
        embedding_model = SafeSentenceTransformerEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            device='cpu'
        )
        st.success("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return
    
    # 2. ë¶€ëª¨-ìì‹ ì „ëµ ì´ˆê¸°í™”
    st.subheader("2. ë¶€ëª¨-ìì‹ ì „ëµ ì´ˆê¸°í™”")
    strategy = ParentChildSearchStrategy(embedding_model)
    
    # 3. ê¸°ì¡´ ë²¡í„°DB ë¡œë“œ ì‹œë„
    st.subheader("3. ê¸°ì¡´ ê³„ì¸µì  ë²¡í„°DB í™•ì¸")
    if strategy.exists():
        st.success("âœ… ê¸°ì¡´ ê³„ì¸µì  ë²¡í„°DB ë°œê²¬")
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        stats = strategy.get_statistics()
        st.info("ğŸ“Š ë²¡í„°DB í†µê³„:")
        st.write(f"- ë¶€ëª¨ ë¬¸ì„œ: {stats['parent_documents']}ê°œ")
        st.write(f"- ìì‹ DB: {stats['child_databases']}ê°œ")
        st.write(f"- ìì‹ ë¬¸ì„œ ì´í•©: {stats['total_child_documents']}ê°œ")
        st.write(f"- ì£¼ì œ: {', '.join(stats['topics'])}")
        
        # ê³„ì¸µ ì •ë³´ í‘œì‹œ
        hierarchy_info = strategy.get_hierarchy_info()
        st.info("ğŸ—ï¸ ê³„ì¸µ êµ¬ì¡°:")
        for parent, children in hierarchy_info['parent_child_mapping'].items():
            st.write(f"- **{parent}**: {', '.join(children)}")
    
    else:
        st.warning("âš ï¸ ê¸°ì¡´ ê³„ì¸µì  ë²¡í„°DBê°€ ì—†ìŠµë‹ˆë‹¤")
        st.info("ğŸ’¡ ìƒˆë¡œìš´ ê³„ì¸µì  ë²¡í„°DBë¥¼ ìƒì„±í•˜ë ¤ë©´ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")
    
    # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    st.subheader("4. ê³„ì¸µì  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    if strategy.exists():
        # ê²€ìƒ‰ ì¿¼ë¦¬ ì…ë ¥
        query = st.text_input(
            "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="ì˜ˆ: bizMOB Client ì„¤ì • ë°©ë²•"
        )
        
        if st.button("ğŸ” ê³„ì¸µì  ê²€ìƒ‰ ì‹¤í–‰") and query:
            with st.spinner("ê³„ì¸µì  ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘..."):
                # ê²€ìƒ‰ ì‹¤í–‰
                results, summary = strategy.search(query)
                
                # ê²°ê³¼ í‘œì‹œ
                st.subheader("ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")
                
                # ìš”ì•½ ì •ë³´
                st.info("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:")
                st.write(f"- ì´ ë¬¸ì„œ: {summary['total_count']}ê°œ")
                st.write(f"- ë¶€ëª¨ ë¬¸ì„œ: {summary['parent_count']}ê°œ")
                st.write(f"- ìì‹ ë¬¸ì„œ: {summary['child_count']}ê°œ")
                st.write(f"- ê´€ë ¨ ì£¼ì œ: {', '.join(summary['topics'])}")
                st.write(f"- í‰ê·  ê´€ë ¨ì„±: {summary['avg_relevance']:.3f}")
                
                # ìƒì„¸ ê²°ê³¼
                if results:
                    st.subheader("ğŸ“„ ìƒì„¸ ê²°ê³¼")
                    for i, doc in enumerate(results[:5]):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                        with st.expander(f"ê²°ê³¼ {i+1}: {doc.metadata.get('file_name', 'Unknown')}"):
                            st.write(f"**íƒ€ì…**: {doc.metadata.get('source_type', 'unknown')}")
                            st.write(f"**ì£¼ì œ**: {doc.metadata.get('topic', 'unknown')}")
                            st.write(f"**ê´€ë ¨ì„± ì ìˆ˜**: {doc.metadata.get('relevance_score', 0):.3f}")
                            st.write(f"**ê°€ì¤‘ ì ìˆ˜**: {doc.metadata.get('weighted_score', 0):.3f}")
                            st.write("**ë‚´ìš©**:")
                            st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
    else:
        st.info("ê³„ì¸µì  ë²¡í„°DBê°€ ì—†ì–´ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    hierarchical_search_example() 