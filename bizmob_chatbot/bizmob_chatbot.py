#!/usr/bin/env python3
"""
bizMOB ì±—ë´‡ - ChromaDB ì „ìš© ë²„ì „
bizmob_chatbot_original.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ChromaDBë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„
"""

import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile
import os
import sys
import json
import pandas as pd
import re
import logging
import glob
import shutil
import subprocess
import time
import warnings
from datetime import datetime
from typing import List, Dict, Any, Optional
import fitz  # PyMuPDF
from pptx import Presentation
from docx import Document as DocxDocument
from safetensors.torch import load_file
import sentence_transformers

# ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore")

# torch.loadë¥¼ safetensors.load_fileë¡œ ì „ì—­ì ìœ¼ë¡œ êµì²´
try:
    import torch
    original_torch_load = torch.load
    
    def safe_torch_load(f, *args, **kwargs):
        """torch.loadë¥¼ safetensors.load_fileë¡œ ëŒ€ì²´í•˜ëŠ” ì•ˆì „í•œ ë¡œë”"""
        try:
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° safetensorsë¡œ ì‹œë„
            if isinstance(f, str) and os.path.exists(f):
                if f.endswith('.safetensors'):
                    return load_file(f)
                else:
                    # ì¼ë°˜ torch íŒŒì¼ì¸ ê²½ìš° ì›ë³¸ ì‚¬ìš©í•˜ë˜ ê²½ê³  ì–µì œ
                    kwargs['weights_only'] = True
                    return original_torch_load(f, *args, **kwargs)
            else:
                # íŒŒì¼ ê°ì²´ì¸ ê²½ìš° ì›ë³¸ ì‚¬ìš©í•˜ë˜ ê²½ê³  ì–µì œ
                kwargs['weights_only'] = True
                return original_torch_load(f, *args, **kwargs)
        except Exception as e:
            st.warning(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ì›ë³¸ torch.load ì‚¬ìš©
            kwargs['weights_only'] = True
            return original_torch_load(f, *args, **kwargs)
    
    # torch.loadë¥¼ ì•ˆì „í•œ ë²„ì „ìœ¼ë¡œ êµì²´
    torch.load = safe_torch_load
    print("âœ… torch.loadë¥¼ safetensors.load_fileë¡œ êµì²´ ì™„ë£Œ")
    
except Exception as e:
    print(f"âš ï¸ torch.load êµì²´ ì‹¤íŒ¨: {e}")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - ë” ê°•ë ¥í•œ safetensors ê°•ì œ ì„¤ì •
os.environ['TORCH_WARN_ON_LOAD'] = '0'
os.environ['TORCH_LOAD_WARN_ONLY'] = '0'
os.environ['PYTORCH_DISABLE_WARNINGS'] = '1'
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ['SAFETENSORS_FAST_GPU'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '0'
os.environ['TORCH_WEIGHTS_ONLY'] = '1'
os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
os.environ['TRANSFORMERS_USE_SAFETENSORS'] = '1'
# ì¶”ê°€ safetensors ê°•ì œ ì„¤ì •
os.environ['SAFETENSORS_FAST_GPU'] = '1'
os.environ['TRANSFORMERS_SAFE_SERIALIZATION'] = '1'
os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
os.environ['TRANSFORMERS_CACHE'] = './model_cache'
os.environ['HF_HOME'] = './huggingface'
os.environ['TORCH_HOME'] = './torch_cache'

# ì™¸ë¶€ ì†ŒìŠ¤ í™•ì¥ì ë¦¬ìŠ¤íŠ¸ ìƒìˆ˜ ì„ ì–¸
EXTERNAL_SOURCE_EXTS = [
    ".py", ".js", ".scss", ".ts", ".vue", ".md", ".txt", ".rst", ".json", ".yaml", ".yml"
]

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    log_dir = "./logs"
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f"bizmob_chatbot_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (UTF-8 ì¸ì½”ë”©)
    file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    
    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ë¡œê±° ì´ˆê¸°í™”
logger = setup_logging()

# ChromaDB ê´€ë ¨ import
try:
    import chromadb
    from langchain_community.vectorstores import Chroma
    CHROMADB_AVAILABLE = True
except ImportError:
    st.error("ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install chromadbë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    CHROMADB_AVAILABLE = False

# NumPy ê°•ì œ ì„¤ì¹˜ í™•ì¸ ë° ì¬ì„¤ì¹˜
try:
    import numpy
    logger.info(f"NumPy version: {numpy.__version__}")
    
    # NumPyê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
    test_array = numpy.array([1, 2, 3])
    logger.info("NumPy test successful")
    
    # NumPyë¥¼ ì „ì—­ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨
    import sys
    sys.modules['numpy'] = numpy
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ NumPy í˜¸í™˜ì„± ê°•í™”
    import os
    os.environ['TOKENIZERS_PARALLELISM'] = 'false'
    os.environ['PYTORCH_DISABLE_WARNINGS'] = '1'
    os.environ['TRANSFORMERS_OFFLINE'] = '0'
    
    # PyTorchì™€ NumPy í˜¸í™˜ì„± ê°•ì œ ì„¤ì •
    try:
        import torch
        if hasattr(torch, 'set_default_tensor_type'):
            torch.set_default_tensor_type('torch.FloatTensor')
        logger.info("PyTorch NumPy compatibility set")
    except Exception as e:
        logger.warning(f"PyTorch NumPy compatibility setup failed: {e}")
    
    # Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ NumPy ì„¤ì • ë° safetensors ê°•ì œ
    try:
        import transformers
        if hasattr(transformers, 'np'):
            transformers.np = numpy
        
        # transformers ë‚´ë¶€ì—ì„œ safetensors ê°•ì œ ì‚¬ìš©
        try:
            import torch
            original_tf_torch_load = torch.load
            
            def safe_tf_torch_load(f, *args, **kwargs):
                """transformersìš© ì•ˆì „í•œ torch.load"""
                try:
                    from safetensors.torch import load_file
                    if isinstance(f, str) and os.path.exists(f):
                        if f.endswith('.safetensors'):
                            return load_file(f)
                        else:
                            kwargs['weights_only'] = True
                            return original_tf_torch_load(f, *args, **kwargs)
                    else:
                        kwargs['weights_only'] = True
                        return original_tf_torch_load(f, *args, **kwargs)
                except Exception:
                    kwargs['weights_only'] = True
                    return original_tf_torch_load(f, *args, **kwargs)
            
            torch.load = safe_tf_torch_load
            logger.info("Transformersìš© torch.loadë¥¼ safetensorsë¡œ êµì²´ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"Transformersìš© torch.load êµì²´ ì‹¤íŒ¨: {e}")
        
        logger.info("Transformers NumPy compatibility set")
    except Exception as e:
        logger.warning(f"Transformers NumPy compatibility setup failed: {e}")
    
    # SentenceTransformersì—ì„œ NumPy ì„¤ì • ë° safetensors ê°•ì œ
    try:
        import sentence_transformers
        if hasattr(sentence_transformers, 'np'):
            sentence_transformers.np = numpy
        
        # sentence_transformers ë‚´ë¶€ì—ì„œ safetensors ê°•ì œ ì‚¬ìš©
        try:
            import torch
            original_st_torch_load = torch.load
            
            def safe_st_torch_load(f, *args, **kwargs):
                """sentence_transformersìš© ì•ˆì „í•œ torch.load"""
                try:
                    from safetensors.torch import load_file
                    if isinstance(f, str) and os.path.exists(f):
                        if f.endswith('.safetensors'):
                            return load_file(f)
                        else:
                            kwargs['weights_only'] = True
                            return original_st_torch_load(f, *args, **kwargs)
                    else:
                        kwargs['weights_only'] = True
                        return original_st_torch_load(f, *args, **kwargs)
                except Exception:
                    kwargs['weights_only'] = True
                    return original_st_torch_load(f, *args, **kwargs)
            
            torch.load = safe_st_torch_load
            logger.info("SentenceTransformersìš© torch.loadë¥¼ safetensorsë¡œ êµì²´ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"SentenceTransformersìš© torch.load êµì²´ ì‹¤íŒ¨: {e}")
        
        logger.info("SentenceTransformers NumPy compatibility set")
    except Exception as e:
        logger.warning(f"SentenceTransformers NumPy compatibility setup failed: {e}")
    
except ImportError:
    logger.error("NumPy is not installed")
    st.error("NumPyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install numpy>=1.26.2ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()
except Exception as e:
    logger.error(f"NumPy error: {e}")
    st.error(f"NumPy ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. pip install numpy>=1.26.2ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# ê¸°íƒ€ í•„ìš”í•œ importë“¤
try:
    from langchain_core.documents.base import Document
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.prompts import PromptTemplate
    from langchain_core.runnables import Runnable, RunnablePassthrough
    from langchain.schema.output_parser import StrOutputParser
    from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredExcelLoader, UnstructuredPowerPointLoader, UnstructuredWordDocumentLoader
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_ollama import OllamaLLM
    from langchain_community.llms import Ollama
    from langchain.chains import RetrievalQA
    from langchain.retrievers import ParentDocumentRetriever
    from langchain.storage import InMemoryStore
    from langchain_core.embeddings import Embeddings
except ImportError as e:
    st.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    st.stop()

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv, dotenv_values
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="bizMOB Platform ì±—ë´‡",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 1rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .user-role {
        background-color: #e3f2fd;
        border: 1px solid #bbdefb;
        border-radius: 5px;
        padding: 0.5rem;
        margin: 1rem 0;
        text-align: center;
        font-weight: bold;
    }
    .admin-only {
        background-color: #fff3e0;
        border: 1px solid #ffcc02;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def check_user_role():
    """ì‚¬ìš©ì ê¶Œí•œ í™•ì¸"""
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì¸ì¦ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ ê´€ë¦¬ì ê¶Œí•œì„ í™•ì¸í•©ë‹ˆë‹¤
    if 'user_role' not in st.session_state:
        # ê¸°ë³¸ê°’ì€ ì¼ë°˜ ì‚¬ìš©ì
        st.session_state.user_role = 'user'
    
    return st.session_state.user_role

def is_admin():
    """ê´€ë¦¬ì ê¶Œí•œ í™•ì¸"""
    return check_user_role() == 'admin'

def show_role_selector():
    """ì‚¬ìš©ì ê¶Œí•œ ì„ íƒê¸°"""
    st.sidebar.subheader("ğŸ‘¤ ì‚¬ìš©ì ê¶Œí•œ")
    
    role_options = {
        'user': 'ì¼ë°˜ ì‚¬ìš©ì',
        'admin': 'ê´€ë¦¬ì'
    }
    
    current_role = st.session_state.get('user_role', 'user')
    selected_role = st.selectbox(
        "ê¶Œí•œ ì„ íƒ",
        options=list(role_options.keys()),
        format_func=lambda x: role_options[x],
        index=0 if current_role == 'user' else 1
    )
    
    if selected_role != current_role:
        st.session_state.user_role = selected_role
        st.rerun()
    
    # í˜„ì¬ ê¶Œí•œ í‘œì‹œ
    role_display = "ê´€ë¦¬ì" if selected_role == 'admin' else "ì¼ë°˜ ì‚¬ìš©ì"
    st.sidebar.markdown(f'<div class="user-role">í˜„ì¬ ê¶Œí•œ: {role_display}</div>', unsafe_allow_html=True)

############################### 1ë‹¨ê³„ : íŒŒì¼ ì—…ë¡œë“œ ë° ê´€ë¦¬ í•¨ìˆ˜ë“¤ ##########################

def save_uploaded_file(uploaded_file: UploadedFile, folder_path: str = "PDF_bizMOB_Guide") -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì§€ì •ëœ í´ë”ì— ì €ì¥í•˜ê³  íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜"""
    try:
        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        file_path = os.path.join(folder_path, uploaded_file.name)
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        return file_path
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def get_supported_file_types() -> dict:
    """ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ê³¼ ì„¤ëª…ì„ ë°˜í™˜"""
    return {
        'pdf': 'PDF ë¬¸ì„œ (.pdf)',
        'xlsx': 'Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸ (.xlsx)',
        'xls': 'Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸ (.xls)',
        'pptx': 'PowerPoint í”„ë ˆì  í…Œì´ì…˜ (.pptx)',
        'ppt': 'PowerPoint í”„ë ˆì  í…Œì´ì…˜ (.ppt)',
        'docx': 'Word ë¬¸ì„œ (.docx)',
        'doc': 'Word ë¬¸ì„œ (.doc)'
    }

def validate_file_type(filename: str) -> bool:
    """íŒŒì¼ í˜•ì‹ì´ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸"""
    supported_extensions = ['.pdf', '.xlsx', '.xls', '.pptx', '.ppt', '.docx', '.doc']
    file_ext = os.path.splitext(filename.lower())[1]
    return file_ext in supported_extensions

def upload_and_process_files() -> bool:
    """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ í•¨ìˆ˜"""
    st.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
    
    # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['pdf', 'xlsx', 'xls', 'pptx', 'ppt', 'docx', 'doc'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_files:
        st.markdown("#### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
        
        success_count = 0
        error_count = 0
        
        for uploaded_file in uploaded_files:
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"ğŸ“„ {uploaded_file.name}")
            
            with col2:
                file_size = len(uploaded_file.getbuffer()) / 1024  # KB
                st.write(f"{file_size:.1f} KB")
            
            with col3:
                if validate_file_type(uploaded_file.name):
                    # íŒŒì¼ ì €ì¥
                    saved_path = save_uploaded_file(uploaded_file)
                    if saved_path:
                        st.success("âœ…")
                        success_count += 1
                    else:
                        st.error("âŒ")
                        error_count += 1
                else:
                    st.error("âŒ")
                    error_count += 1
        
        # ê²°ê³¼ ìš”ì•½
        if success_count > 0:
            st.success(f"âœ… {success_count}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì˜µì…˜
            if st.button("ğŸ”„ ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™”", type="primary"):
                if initialize_vector_db_with_documents():
                    st.session_state.vector_db_initialized = True
                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ìƒˆë¡œìš´ íŒŒì¼ë“¤ë¡œ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                else:
                    st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        if error_count > 0:
            st.error(f"âŒ {error_count}ê°œ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return success_count > 0
    
    return False

def list_uploaded_files(folder_path: str = "PDF_bizMOB_Guide") -> dict:
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ í˜•ì‹ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ë°˜í™˜"""
    if not os.path.exists(folder_path):
        return {}
    
    files_by_type = {
        'PDF': [],
        'Excel': [],
        'PowerPoint': [],
        'Word': []
    }
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = {
        '*.pdf': 'PDF',
        '*.xlsx': 'Excel',
        '*.xls': 'Excel',
        '*.pptx': 'PowerPoint',
        '*.ppt': 'PowerPoint',
        '*.docx': 'Word',
        '*.doc': 'Word'
    }
    
    for pattern, file_type in supported_extensions.items():
        files = glob.glob(os.path.join(folder_path, pattern))
        for file_path in files:
            file_size = os.path.getsize(file_path) / 1024  # KB
            files_by_type[file_type].append({
                'name': os.path.basename(file_path),
                'path': file_path,
                'size': file_size
            })
    
    return files_by_type

def safe_key(filename: str) -> str:
    """íŒŒì¼ëª…ì„ ì•ˆì „í•œ session state í‚¤ë¡œ ë³€í™˜"""
    # íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜
    safe_name = re.sub(r'[^a-zA-Z0-9_]', '_', filename)
    # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•Šë„ë¡ prefix ì¶”ê°€
    if safe_name and safe_name[0].isdigit():
        safe_name = 'file_' + safe_name
    return safe_name

def delete_file(file_path: str) -> bool:
    """íŒŒì¼ ì‚­ì œ í•¨ìˆ˜"""
    try:
        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(file_path):
            st.error(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return False
        
        # íŒŒì¼ ì‚­ì œ
        os.remove(file_path)
        
        # ì‚­ì œ í™•ì¸
        if os.path.exists(file_path):
            st.error(f"íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {file_path}")
            return False
        
        return True
    except PermissionError:
        st.error(f"íŒŒì¼ ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    except Exception as e:
        st.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def delete_file_with_confirmation(file_path: str, file_name: str) -> bool:
    """í™•ì¸ í›„ íŒŒì¼ ì‚­ì œ í•¨ìˆ˜"""
    # ì‚­ì œ í™•ì¸ì„ ìœ„í•œ session state í‚¤
    confirm_key = f"confirm_delete_{file_name}"
    
    if confirm_key not in st.session_state:
        st.session_state[confirm_key] = False
    
    if not st.session_state[confirm_key]:
        # ì‚­ì œ í™•ì¸ ë²„íŠ¼
        if st.button(f"ğŸ—‘ï¸ ì‚­ì œ í™•ì¸", key=f"confirm_{file_name}"):
            st.session_state[confirm_key] = True
            return False
        return False
    else:
        # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
        if delete_file(file_path):
            st.success(f"âœ… {file_name} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            # session state ì •ë¦¬
            del st.session_state[confirm_key]
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì œì•ˆ
            st.warning("âš ï¸ ì‚­ì œëœ íŒŒì¼ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜ë˜ë ¤ë©´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", key=f"reinit_after_delete_{file_name}"):
                if initialize_vector_db():
                    st.session_state.vector_db_initialized = True
                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        else:
            st.error(f"âŒ {file_name} íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            # session state ì •ë¦¬
            del st.session_state[confirm_key]
            return False

def manage_uploaded_files() -> None:
    """ì—…ë¡œë“œëœ íŒŒì¼ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤"""
    st.markdown("### ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼ ê´€ë¦¬")
    
    # ì‹ ê·œ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
    with st.expander("ğŸ“ ì‹ ê·œ íŒŒì¼ ì—…ë¡œë“œ", expanded=False):
        st.markdown("#### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        st.markdown("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
        
        # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
        uploaded_files = st.file_uploader(
            "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['pdf', 'xlsx', 'xls', 'pptx', 'ppt', 'docx', 'doc'],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="file_manager_uploader"
        )
        
        if uploaded_files:
            st.markdown("#### ğŸ“‹ ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡")
            
            success_count = 0
            error_count = 0
            
            for uploaded_file in uploaded_files:
                col1, col2, col3 = st.columns([3, 1, 1])
                
                with col1:
                    st.write(f"ğŸ“„ {uploaded_file.name}")
                
                with col2:
                    file_size = len(uploaded_file.getbuffer()) / 1024  # KB
                    st.write(f"{file_size:.1f} KB")
                
                with col3:
                    if validate_file_type(uploaded_file.name):
                        # íŒŒì¼ ì €ì¥
                        saved_path = save_uploaded_file(uploaded_file)
                        if saved_path:
                            st.success("âœ…")
                            success_count += 1
                        else:
                            st.error("âŒ")
                            error_count += 1
                    else:
                        st.error("âŒ")
                        error_count += 1
            
            # ê²°ê³¼ ìš”ì•½
            if success_count > 0:
                st.success(f"âœ… {success_count}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì˜µì…˜
                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", type="primary", key="file_manager_reinit"):
                        if initialize_vector_db_with_documents():
                            st.session_state.vector_db_initialized = True
                            st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                with col2:
                    if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨", key="file_manager_refresh"):
                        pass  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ì€ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìˆ˜í–‰
            
            if error_count > 0:
                st.error(f"âŒ {error_count}ê°œ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    files_by_type = list_uploaded_files()
    
    if not any(files_by_type.values()):
        st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.markdown("### ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹")
        st.markdown("- **PDF** (.pdf): ë§¤ë‰´ì–¼, ê°€ì´ë“œ ë¬¸ì„œ")
        st.markdown("- **Excel** (.xlsx, .xls): ë°ì´í„° ì‹œíŠ¸, ë¶„ì„ ìë£Œ")
        st.markdown("- **PowerPoint** (.pptx, .ppt): í”„ë ˆì  í…Œì´ì…˜, êµìœ¡ ìë£Œ")
        st.markdown("- **Word** (.docx, .doc): ë³´ê³ ì„œ, ë¬¸ì„œ, ë§¤ë‰´ì–¼")
        return
    
    # íŒŒì¼ í†µê³„ ì •ë³´
    total_files = sum(len(files) for files in files_by_type.values())
    total_size = sum(sum(file_info['size'] for file_info in files) for files in files_by_type.values())
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“ ì´ íŒŒì¼ ìˆ˜", f"{total_files}ê°œ")
    with col2:
        st.metric("ğŸ’¾ ì´ ìš©ëŸ‰", f"{total_size:.1f} KB")
    with col3:
        if check_vector_db_exists():
            st.success("âœ… ë²¡í„°DB ì¤€ë¹„ë¨")
        else:
            st.warning("âš ï¸ ë²¡í„°DB ë¯¸ì¤€ë¹„")
    
    # ë²¡í„°DB ì¬ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™”", type="primary", key="file_manager_main_reinit"):
        if initialize_vector_db_with_documents():
            st.session_state.vector_db_initialized = True
            st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # íŒŒì¼ í˜•ì‹ë³„ë¡œ íƒ­ ìƒì„± (ìˆ˜ì •)
    file_types_with_files = [(file_type, files) for file_type, files in files_by_type.items() if files]
    tab_names = [f"{file_type} ({len(files)})" for file_type, files in file_types_with_files]
    if tab_names:
        tabs = st.tabs(tab_names)
        for i, (file_type, files) in enumerate(file_types_with_files):
            with tabs[i]:
                st.markdown(f"#### {file_type} íŒŒì¼ ëª©ë¡")
                
                for file_info in files:
                    with st.expander(f"ğŸ“„ {file_info['name']} ({file_info['size']:.1f} KB)"):
                        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                        
                        with col1:
                            st.write(f"**íŒŒì¼ëª…:** {file_info['name']}")
                            st.write(f"**í¬ê¸°:** {file_info['size']:.1f} KB")
                            st.write(f"**ê²½ë¡œ:** {file_info['path']}")
                        
                        with col2:
                            # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            safe_download_key = safe_key(file_info['name'])
                            with open(file_info['path'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                                    data=f.read(),
                                    file_name=file_info['name'],
                                    key=f"download_{safe_download_key}"
                                )
                        
                        with col3:
                            # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼
                            safe_preview_key = safe_key(file_info['name'])
                            if st.button("ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°", key=f"preview_{safe_preview_key}"):
                                st.session_state.preview_file = file_info['path']
                                st.session_state.preview_file_type = file_type
                                st.session_state.preview_file_name = file_info['name']
                        
                        with col4:
                            # íŒŒì¼ ì‚­ì œ ë²„íŠ¼ - ì•ˆì „í•œ í‚¤ ì‚¬ìš©
                            safe_file_key = safe_key(file_info['name'])
                            delete_key = f"delete_{safe_file_key}"
                            
                            if delete_key not in st.session_state:
                                st.session_state[delete_key] = False
                            
                            if not st.session_state[delete_key]:
                                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"btn_{safe_file_key}"):
                                    st.session_state[delete_key] = True
                            else:
                                st.warning(f"ì •ë§ë¡œ '{file_info['name']}' íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                                col_confirm1, col_confirm2 = st.columns(2)
                                with col_confirm1:
                                    if st.button("âœ… í™•ì¸", key=f"confirm_{safe_file_key}"):
                                        if delete_file(file_info['path']):
                                            st.success(f"âœ… {file_info['name']} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                            # ë²¡í„°DB ì¬ì´ˆê¸°í™” ì œì•ˆ
                                            st.warning("âš ï¸ ì‚­ì œëœ íŒŒì¼ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜ë˜ë ¤ë©´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                                            if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", key=f"reinit_{safe_file_key}"):
                                                if initialize_vector_db_with_documents():
                                                    st.session_state.vector_db_initialized = True
                                                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                            # session state ì •ë¦¬
                                            del st.session_state[delete_key]
                                        else:
                                            st.error(f"âŒ {file_info['name']} íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                            del st.session_state[delete_key]
                                with col_confirm2:
                                    if st.button("âŒ ì·¨ì†Œ", key=f"cancel_{safe_file_key}"):
                                        del st.session_state[delete_key]
                    
                    # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜
                    if 'preview_file' in st.session_state and st.session_state.preview_file_type == file_type:
                        st.markdown("---")
                        st.markdown(f"#### ğŸ‘ï¸ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°: {st.session_state.preview_file_name}")
                        
                        try:
                            if file_type == 'PDF':
                                # PDF ë¯¸ë¦¬ë³´ê¸°
                                images = convert_pdf_to_images(st.session_state.preview_file)
                                if images:
                                    st.image(images[0], caption="ì²« í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°", width=400)
                                    st.info(f"ì´ {len(images)}í˜ì´ì§€")
                            
                            elif file_type == 'Excel':
                                # Excel ë¯¸ë¦¬ë³´ê¸°
                                excel_file = pd.ExcelFile(st.session_state.preview_file)
                                sheet_names = excel_file.sheet_names
                                st.write(f"**ì‹œíŠ¸ ëª©ë¡:** {', '.join(sheet_names)}")
                                
                                if sheet_names:
                                    selected_sheet = st.selectbox("ì‹œíŠ¸ ì„ íƒ", sheet_names)
                                    df = pd.read_excel(st.session_state.preview_file, sheet_name=selected_sheet)
                                    st.dataframe(df.head(10), use_container_width=True)
                                    st.info(f"ì´ {len(df)}í–‰, {len(df.columns)}ì—´")
                            
                            elif file_type == 'PowerPoint':
                                # PowerPoint ë¯¸ë¦¬ë³´ê¸°
                                prs = Presentation(st.session_state.preview_file)
                                st.write(f"**ì´ ìŠ¬ë¼ì´ë“œ ìˆ˜:** {len(prs.slides)}")
                                
                                if prs.slides:
                                    slide_content = ""
                                    for i, slide in enumerate(prs.slides[:3]):  # ì²˜ìŒ 3ê°œ ìŠ¬ë¼ì´ë“œë§Œ
                                        slide_content += f"**ìŠ¬ë¼ì´ë“œ {i+1}:**\n"
                                        for shape in slide.shapes:
                                            if hasattr(shape, "text") and shape.text.strip():
                                                slide_content += f"{shape.text}\n"
                                        slide_content += "\n"
                                    
                                    st.text_area("ìŠ¬ë¼ì´ë“œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", slide_content, height=200)
                            
                            elif file_type == 'Word':
                                # Word ë¯¸ë¦¬ë³´ê¸°
                                doc = DocxDocument(st.session_state.preview_file)
                                st.write(f"**ì œëª©:** {doc.core_properties.title or 'ì œëª© ì—†ìŒ'}")
                                st.write(f"**ì‘ì„±ì:** {doc.core_properties.author or 'ì‘ì„±ì ì—†ìŒ'}")
                                
                                # ì²˜ìŒ ëª‡ ë‹¨ë½ë§Œ ë¯¸ë¦¬ë³´ê¸°
                                preview_text = ""
                                for para in doc.paragraphs[:10]:
                                    if para.text.strip():
                                        preview_text += para.text + "\n\n"
                                
                                st.text_area("ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", preview_text, height=200)
                        
                        except Exception as e:
                            st.error(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        
                        # ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸° ë²„íŠ¼
                        if st.button("âŒ ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸°"):
                            del st.session_state.preview_file
                            del st.session_state.preview_file_type
                            del st.session_state.preview_file_name 

############################### 1ë‹¨ê³„ : PDF ë¬¸ì„œë¥¼ ë²¡í„°DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë“¤ ##########################

## 1: PDF_bizMOB_Guide í´ë”ì—ì„œ ëª¨ë“  ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì•„ì„œ Documentë¡œ ë³€í™˜
def load_all_documents_from_folder(folder_path: str = "PDF_bizMOB_Guide") -> List[Document]:
    documents = []
    
    if not os.path.exists(folder_path):
        st.error(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return documents
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = {
        '*.pdf': 'PDF',
        '*.xlsx': 'Excel',
        '*.xls': 'Excel',
        '*.pptx': 'PowerPoint',
        '*.ppt': 'PowerPoint',
        '*.docx': 'Word',
        '*.doc': 'Word'
    }
    
    all_files = []
    for pattern, file_type in supported_extensions.items():
        files = glob.glob(os.path.join(folder_path, pattern))
        all_files.extend([(f, file_type) for f in files])
    
    if not all_files:
        st.warning(f"{folder_path} í´ë”ì— ì§€ì›í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
        return documents
    
    for file_path, file_type in all_files:
        try:
            st.info(f"{file_type} íŒŒì¼ ë¡œë”© ì¤‘: {os.path.basename(file_path)}")
            
            if file_type == 'PDF':
                loader = PyMuPDFLoader(file_path)
                doc = loader.load()
            elif file_type == 'Excel':
                doc = load_excel_file(file_path)
            elif file_type == 'PowerPoint':
                doc = load_powerpoint_file(file_path)
            elif file_type == 'Word':
                doc = load_word_file(file_path)
            
            for d in doc:
                d.metadata['file_path'] = file_path
                d.metadata['file_name'] = os.path.basename(file_path)
                d.metadata['file_type'] = file_type
            
            documents.extend(doc)
            st.success(f"âœ… {os.path.basename(file_path)} ({file_type}) ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            st.error(f"âŒ {os.path.basename(file_path)} ({file_type}) ë¡œë”© ì‹¤íŒ¨: {str(e)}")
    
    # ì™¸ë¶€ ì†ŒìŠ¤ ì½”ë“œ(.py, .md ë“±)ë„ í¬í•¨
    ext_src_dir = "external_sources"
    if os.path.exists(ext_src_dir):
        for repo in os.listdir(ext_src_dir):
            repo_path = os.path.join(ext_src_dir, repo)
            for ext in EXTERNAL_SOURCE_EXTS:
                for file in glob.glob(f"{repo_path}/**/*{ext}", recursive=True):
                    try:
                        if os.path.getsize(file) > 2*1024*1024:
                            st.warning(f"{file} íŒŒì¼ì€ 2MBë¥¼ ì´ˆê³¼í•˜ì—¬ ë²¡í„°DBì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            continue
                        with open(file, "r", encoding="utf-8", errors="ignore") as f:
                            content = f.read()
                        doc = Document(
                            page_content=content,
                            metadata={
                                'file_path': file,
                                'file_name': os.path.basename(file),
                                'file_type': 'Source',
                                'repo': repo
                            }
                        )
                        documents.append(doc)
                    except Exception as e:
                        st.warning(f"{file} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return documents

def load_excel_file(file_path: str) -> List[Document]:
    """Excel íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # Excel íŒŒì¼ ì½ê¸°
        excel_file = pd.ExcelFile(file_path)
        
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            # ë°ì´í„°í”„ë ˆì„ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            text_content = f"ì‹œíŠ¸ëª…: {sheet_name}\n\n"
            
            # í—¤ë” ì •ë³´ ì¶”ê°€
            if not df.empty:
                text_content += f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}\n\n"
                
                # ë°ì´í„° ë‚´ìš© ì¶”ê°€ (ì²˜ìŒ 100í–‰ê¹Œì§€ë§Œ)
                for idx, row in df.head(100).iterrows():
                    row_text = " | ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
                    if row_text.strip():
                        text_content += f"í–‰ {idx+1}: {row_text}\n"
            
            # Document ìƒì„±
            doc = Document(
                page_content=text_content,
                metadata={
                    'file_path': file_path,
                    'file_name': os.path.basename(file_path),
                    'file_type': 'Excel',
                    'sheet_name': sheet_name
                }
            )
            documents.append(doc)
            
    except Exception as e:
        st.error(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

def load_powerpoint_file(file_path: str) -> List[Document]:
    """PowerPoint íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # PowerPoint íŒŒì¼ ì½ê¸°
        prs = Presentation(file_path)
        
        for slide_num, slide in enumerate(prs.slides, 1):
            text_content = f"ìŠ¬ë¼ì´ë“œ {slide_num}:\n\n"
            
            # ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    text_content += f"{shape.text}\n\n"
            
            # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ Document ìƒì„±
            if text_content.strip() and text_content != f"ìŠ¬ë¼ì´ë“œ {slide_num}:\n\n":
                doc = Document(
                    page_content=text_content,
                    metadata={
                        'file_path': file_path,
                        'file_name': os.path.basename(file_path),
                        'file_type': 'PowerPoint',
                        'slide_number': slide_num
                    }
                )
                documents.append(doc)
                
    except Exception as e:
        st.error(f"PowerPoint íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

def load_word_file(file_path: str) -> List[Document]:
    """Word íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # Word íŒŒì¼ ì½ê¸°
        doc = DocxDocument(file_path)
        
        # ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ Documentë¡œ ì²˜ë¦¬
        text_content = ""
        
        # ì œëª© ì •ë³´ ì¶”ê°€
        if doc.core_properties.title:
            text_content += f"ì œëª©: {doc.core_properties.title}\n\n"
        
        # ë‹¨ë½ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for para in doc.paragraphs:
            if para.text.strip():
                text_content += para.text + "\n\n"
        
        # í‘œ ë‚´ìš© ì¶”ì¶œ
        for table in doc.tables:
            text_content += "í‘œ ë‚´ìš©:\n"
            for row in table.rows:
                row_text = " | ".join([cell.text for cell in row.cells if cell.text.strip()])
                if row_text.strip():
                    text_content += row_text + "\n"
            text_content += "\n"
        
        # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ Document ìƒì„±
        if text_content.strip():
            doc_chunk = Document(
                page_content=text_content,
                metadata={
                    'file_path': file_path,
                    'file_name': os.path.basename(file_path),
                    'file_type': 'Word',
                    'title': doc.core_properties.title or 'Unknown',
                    'author': doc.core_properties.author or 'Unknown'
                }
            )
            documents.append(doc_chunk)
            
    except Exception as e:
        st.error(f"Word íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

## 2: Documentë¥¼ ë” ì‘ì€ documentë¡œ ë³€í™˜
def chunk_documents(documents: List[Document]) -> List[Document]:
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    return text_splitter.split_documents(documents)

## 3: Documentë¥¼ ë²¡í„°DBë¡œ ì €ì¥ (ChromaDB ì‚¬ìš©)
def save_to_vector_store(documents: List[Document]) -> None:
    try:
        # ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = get_embedding_model()
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        
        st.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {selected_embedding}")
        
        # ChromaDBì— ì €ì¥
        save_to_chroma_store(documents)
        st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ (ChromaDB ì‚¬ìš©)")
    except Exception as e:
        st.error(f"âŒ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

## 4: ë²¡í„°DB ì´ˆê¸°í™” í•¨ìˆ˜ (ë¬¸ì„œ ë¡œë”© í¬í•¨)
def initialize_vector_db_with_documents():
    """PDF_bizMOB_Guide í´ë”ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„°DBë¥¼ ì´ˆê¸°í™”"""
    with st.spinner("bizMOB Platform ê°€ì´ë“œ ë¬¸ì„œë“¤ì„ ë¡œë”©í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
        # ëª¨ë“  ë¬¸ì„œë“¤ ë¡œë“œ (PDF, Excel, PowerPoint)
        documents = load_all_documents_from_folder()
        
        if not documents:
            st.error("ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ë¬¸ì„œ ì²­í‚¹
        st.info("ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ì¤‘...")
        chunked_documents = chunk_documents(documents)
        st.success(f"âœ… {len(chunked_documents)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")
        
        # ë²¡í„°DB ì €ì¥
        st.info("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì¤‘...")
        save_to_chroma_store(chunked_documents)
        
        # ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥
        try:
            model_info = {
                'ai_model': st.session_state.get('selected_model', 'hyperclovax'),
                'embedding_model': st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask'),
                'timestamp': pd.Timestamp.now().isoformat()
            }
            
            import json
            with open('vector_db_model_info.json', 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            
            st.success("âœ… ëª¨ë¸ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ ëª¨ë¸ ì •ë³´ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return True

## 4-1: ë²¡í„°DB ì´ˆê¸°í™” í•¨ìˆ˜ (ChromaDBë§Œ ì´ˆê¸°í™”)
def initialize_vector_db():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    logger.info("Vector database initialization started")
    
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return False
    
    try:
        # ChromaDB ë””ë ‰í† ë¦¬ ìƒì„±
        chroma_path = get_chroma_db_path()
        logger.info(f"ChromaDB path: {chroma_path}")
        os.makedirs(chroma_path, exist_ok=True)
        logger.info("ChromaDB directory created successfully")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        import chromadb
        import time
        
        # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œë„
        max_retries = 3
        client = None
        
        for attempt in range(max_retries):
            try:
                client = chromadb.PersistentClient(
                    path=chroma_path,
                    settings=chromadb.config.Settings(
                        allow_reset=True,
                        anonymized_telemetry=False
                    )
                )
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"Client connection attempt {attempt + 1} failed: {e}")
                    time.sleep(1)
                else:
                    raise e
        
        if client is None:
            raise Exception("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
        
        collection_name = "bizmob_documents"
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
        try:
            client.delete_collection(name=collection_name)
            logger.info("Existing collection deleted")
            time.sleep(0.5)  # ì ì‹œ ëŒ€ê¸°
        except:
            logger.info("No existing collection to delete")
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        collection = client.create_collection(name=collection_name)
        logger.info("New collection created successfully")
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        model_info = {
            'ai_model': st.session_state.get('selected_model', 'hyperclovax'),
            'embedding_model': st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask'),
            'timestamp': pd.Timestamp.now().isoformat()
        }
        logger.info(f"Model info: {model_info}")
        
        model_info_path = get_model_info_path()
        logger.info(f"Model info file path: {model_info_path}")
        
        with open(model_info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        st.session_state.vector_db_initialized = True
        st.success("âœ… ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("Vector database initialization successful")
        return True
        
    except Exception as e:
        error_msg = f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
        logger.error(f"Vector database initialization failed: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")
        return False

def save_to_chroma_store(documents: list) -> None:
    """ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥"""
    logger.info(f"Vector database save started - document count: {len(documents)}")
    
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return
    
    try:
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        import os
        os.environ['TOKENIZERS_PARALLELISM'] = 'false'
        os.environ['PYTORCH_DISABLE_WARNINGS'] = '1'
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        logger.info(f"Loading embedding model: {selected_embedding}")
        
        try:
            embeddings = HuggingFaceEmbeddings(model_name=selected_embedding)
            logger.info("Embedding model loaded successfully")
        except Exception as e:
            logger.error(f"Embedding model loading failed: {e}")
            st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì§€ì†ì  ì €ì¥ì„ ìœ„í•´ ê²½ë¡œ ì§€ì •)
        try:
            import chromadb
            import time
            chroma_path = get_chroma_db_path()
            os.makedirs(chroma_path, exist_ok=True)
            
            # session_stateì—ì„œ ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í™•ì¸
            if 'chroma_client' in st.session_state:
                try:
                    # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í•´ì œ ì‹œë„
                    del st.session_state.chroma_client
                    import gc
                    gc.collect()
                    time.sleep(0.5)
                except:
                    pass
            
            # ì§€ì†ì  ì €ì¥ì„ ìœ„í•œ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì¬ì‹œë„ ë¡œì§)
            max_retries = 3
            client = None
            
            for attempt in range(max_retries):
                try:
                    client = chromadb.PersistentClient(
                        path=chroma_path,
                        settings=chromadb.config.Settings(
                            allow_reset=True,
                            anonymized_telemetry=False
                        )
                    )
                    # session_stateì— í´ë¼ì´ì–¸íŠ¸ ì €ì¥
                    st.session_state.chroma_client = client
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"Client connection attempt {attempt + 1} failed: {e}")
                        time.sleep(1)
                    else:
                        raise e
            
            if client is None:
                raise Exception("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
            
            collection_name = "bizmob_documents"
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            try:
                collection = client.get_collection(name=collection_name)
                logger.info("Existing collection found")
            except:
                collection = client.create_collection(name=collection_name)
                logger.info("New collection created")
            
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (í…ìŠ¤íŠ¸ ì •ì œ)
            documents_texts = []
            documents_metadatas = []
            documents_ids = []
            
            for i, doc in enumerate(documents):
                # í…ìŠ¤íŠ¸ ì •ì œ (íŠ¹ìˆ˜ë¬¸ì ë° ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
                clean_text = doc.page_content.strip()
                if clean_text:
                    documents_texts.append(clean_text)
                    documents_metadatas.append(doc.metadata)
                    documents_ids.append(f"doc_{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            
            if not documents_texts:
                st.warning("ì €ì¥í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì„ë² ë”© ìƒì„±
            logger.info("Generating embeddings...")
            embeddings_list = embeddings.embed_documents(documents_texts)
            logger.info(f"Generated {len(embeddings_list)} embeddings")
            
            # ChromaDBì— ì €ì¥
            collection.add(
                documents=documents_texts,
                embeddings=embeddings_list,
                metadatas=documents_metadatas,
                ids=documents_ids
            )
            
            logger.info("ChromaDB document save completed")
            st.success(f"âœ… {len(documents_texts)}ê°œ ë¬¸ì„œê°€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ëœ ë¬¸ì„œ ìˆ˜ í™•ì¸
            try:
                count = collection.count()
                logger.info(f"Total documents in collection: {count}")
                st.info(f"ğŸ“Š í˜„ì¬ ë²¡í„° DBì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {count}ê°œ")
                
                # ì €ì¥ëœ ë¬¸ì„œ ìƒ˜í”Œ í™•ì¸
                if count > 0:
                    sample_results = collection.get(limit=1)
                    if sample_results['documents']:
                        sample_text = sample_results['documents'][0][:100]
                        logger.info(f"Sample document: {sample_text}...")
                        st.info(f"ğŸ“ ì €ì¥ëœ ë¬¸ì„œ ìƒ˜í”Œ: {sample_text}...")
                
            except Exception as e:
                logger.warning(f"Could not get collection count: {e}")
            
        except Exception as e:
            logger.error(f"ChromaDB save failed: {e}")
            st.error(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return
        
    except Exception as e:
        error_msg = f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}"
        logger.error(f"Vector database save failed: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")

def load_chroma_store():
    """ChromaDBì—ì„œ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
    logger.info("ChromaDB vector store loading started")
    
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return None
    
    try:
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        embeddings = get_embedding_model()
        logger.info("Embedding model loaded")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì§€ì†ì  ì €ì¥ì„ ìœ„í•´ ê²½ë¡œ ì§€ì •)
        import chromadb
        import time
        chroma_path = get_chroma_db_path()
        
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(chroma_path):
            os.makedirs(chroma_path, exist_ok=True)
            logger.info(f"Created ChromaDB directory: {chroma_path}")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (session_stateì— ì €ì¥í•˜ì§€ ì•ŠìŒ - í•„ìš”í•  ë•Œë§Œ ì—°ê²°)
        max_retries = 3
        client = None
        
        for attempt in range(max_retries):
            try:
                client = chromadb.PersistentClient(
                    path=chroma_path,
                    settings=chromadb.config.Settings(
                        allow_reset=True,
                        anonymized_telemetry=False
                    )
                )
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"Client connection attempt {attempt + 1} failed: {e}")
                    time.sleep(1)
                else:
                    raise e
        
        if client is None:
            raise Exception("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
        
        collection_name = "bizmob_documents"
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
        try:
            collection = client.get_collection(name=collection_name)
            logger.info("Existing collection found")
        except:
            logger.warning("Collection not found, creating new one")
            collection = client.create_collection(name=collection_name)
        
        # LangChain Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        vector_store = Chroma(
            client=client,
            collection_name=collection_name,
            embedding_function=embeddings
        )
        logger.info("ChromaDB vector store creation completed")
        
        # ë²¡í„° ìŠ¤í† ì–´ ì •ë³´ ë¡œê¹…
        try:
            collection_count = collection.count()
            logger.info(f"ChromaDB collection document count: {collection_count}")
        except Exception as e:
            logger.warning(f"Collection info check failed: {e}")
        
        return vector_store
    except Exception as e:
        error_msg = f"ChromaDB ë¡œë“œ ì‹¤íŒ¨: {e}"
        logger.error(f"ChromaDB load failed: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")
        return None

############################### 2ë‹¨ê³„ : RAG ê¸°ëŠ¥ êµ¬í˜„ê³¼ ê´€ë ¨ëœ í•¨ìˆ˜ë“¤ ##########################

## ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬
@st.cache_data
def process_question(user_question):
    try:
        # RAG ì²´ì¸ ì„ ì–¸
        chain = get_rag_chain()
        if chain is None:
            st.error("RAG ì²´ì¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None, []
        
        # ì§ˆë¬¸ë§Œ ì „ë‹¬í•˜ì—¬ RAG ì²´ì¸ ì‹¤í–‰
        response = chain.invoke(user_question)
        
        # ê´€ë ¨ ë¬¸ì„œëŠ” ë³„ë„ë¡œ ê²€ìƒ‰ (ì°¸ì¡°ìš©)
        embeddings = get_embedding_model()
        vector_store = load_chroma_store()
        if vector_store:
            retriever = vector_store.as_retriever(search_kwargs={"k": 3})
            retrieve_docs: List[Document] = retriever.invoke(user_question)
        else:
            retrieve_docs = []

        return response, retrieve_docs
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, []

def get_rag_chain() -> Runnable:
    """RAG ì²´ì¸ ìƒì„±"""
    try:
        # ì„ íƒëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        selected_model = st.session_state.get('selected_model', 'hyperclovax')
        
        # Ollama LLM ì´ˆê¸°í™”
        llm = OllamaLLM(
            model=selected_model,
            temperature=0.1,
            top_p=0.9,
            max_tokens=2048
        )
        
        # ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = get_embedding_model()
        
        # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
        vector_store = load_chroma_store()
        if vector_store is None:
            return None
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """ë‹¹ì‹ ì€ bizMOB Platform ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        
        prompt = PromptTemplate(
            input_variables=["context", "question"],
            template=template
        )
        
        # RAG ì²´ì¸ ìƒì„±
        chain = (
            {"context": vector_store.as_retriever(search_kwargs={"k": 3}), "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        return chain
        
    except Exception as e:
        st.error(f"RAG ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

############################### 3ë‹¨ê³„ : ì‘ë‹µê²°ê³¼ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ë³´ë„ë¡ ë„ì™€ì£¼ëŠ” í•¨ìˆ˜ ##########################

@st.cache_data(show_spinner=False)
def convert_pdf_to_images(pdf_path: str, dpi: int = 250) -> List[str]:
    doc = fitz.open(pdf_path)  # ë¬¸ì„œ ì—´ê¸°
    image_paths = []
    
    # ì´ë¯¸ì§€ ì €ì¥ìš© í´ë” ìƒì„±
    output_folder = "PDF_ì´ë¯¸ì§€_bizmob"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for page_num in range(len(doc)):  # ê° í˜ì´ì§€ë¥¼ ìˆœíšŒ
        page = doc.load_page(page_num)  # í˜ì´ì§€ ë¡œë“œ

        zoom = dpi / 72  # 72ì´ ë””í´íŠ¸ DPI
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat) # type: ignore

        image_path = os.path.join(output_folder, f"page_{page_num + 1}.png")  # í˜ì´ì§€ ì´ë¯¸ì§€ ì €ì¥ page_1.png, page_2.png, etc.
        pix.save(image_path)  # PNG í˜•íƒœë¡œ ì €ì¥
        image_paths.append(image_path)  # ê²½ë¡œë¥¼ ì €ì¥
        
    return image_paths

def display_pdf_page(image_path: str, page_number: int) -> None:
    try:
        image_bytes = open(image_path, "rb").read()  # íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì¸ì‹
        st.image(image_bytes, caption=f"Page {page_number}", output_format="PNG", width=600)
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def natural_sort_key(s):
    return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]

def check_vector_db_exists():
    """ë²¡í„°DBê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    return os.path.exists(get_chroma_db_path())

def load_saved_model_info():
    """ì €ì¥ëœ ëª¨ë¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜´"""
    try:
        if os.path.exists('vector_db_model_info.json'):
            import json
            with open('vector_db_model_info.json', 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            return model_info
        return None
    except Exception as e:
        st.warning(f"âš ï¸ ì €ì¥ëœ ëª¨ë¸ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

def check_ollama_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ í™•ì¸"""
    try:
        import subprocess
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if result.returncode == 0:
            return True
        return False
    except:
        return False

def get_ollama_models():
    """Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
    try:
        import subprocess
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            models = []
            for line in lines[1:]:  # ì²« ë²ˆì§¸ ì¤„ì€ í—¤ë”ì´ë¯€ë¡œ ì œì™¸
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 2:
                        model_name = parts[0]
                        model_size = parts[1] if len(parts) > 1 else "Unknown"
                        models.append({
                            'name': model_name,
                            'size': model_size
                        })
            return models
        return []
    except Exception as e:
        st.error(f"Ollama ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return []

def get_available_embedding_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜"""
    return {
        'sentence-transformers/all-MiniLM-L6-v2': {
            'name': 'all-MiniLM-L6-v2',
            'description': 'ì˜ì–´ ì „ìš©, ë¹ ë¥´ê³  ê°€ë²¼ìš´ ëª¨ë¸',
            'language': 'English',
            'size': 'Small'
        },
        'jhgan/ko-sroberta-multitask': {
            'name': 'ko-sroberta-multitask',
            'description': 'í•œêµ­ì–´ ì „ìš©, ë‹¤ì¤‘ ì‘ì—… ëª¨ë¸',
            'language': 'Korean',
            'size': 'Medium'
        },
        'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': {
            'name': 'paraphrase-multilingual-MiniLM-L12-v2',
            'description': 'ë‹¤êµ­ì–´ ì§€ì›, ê· í˜•ì¡íŒ ì„±ëŠ¥',
            'language': 'Multilingual',
            'size': 'Medium'
        },
        'sentence-transformers/all-mpnet-base-v2': {
            'name': 'all-mpnet-base-v2',
            'description': 'ì˜ì–´ ì „ìš©, ê³ í’ˆì§ˆ ì„ë² ë”©',
            'language': 'English',
            'size': 'Large'
        },
        'intfloat/multilingual-e5-large': {
            'name': 'multilingual-e5-large',
            'description': 'ë‹¤êµ­ì–´ ì§€ì›, ê³ í’ˆì§ˆ ì„ë² ë”©',
            'language': 'Multilingual',
            'size': 'Large'
        }
    }

class SafeSentenceTransformerEmbeddings(Embeddings):
    """safetensorsë¥¼ ì‚¬ìš©í•˜ëŠ” ì•ˆì „í•œ ì„ë² ë”© í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str, device: str = 'cpu'):
        self.model_name = model_name
        self.device = device
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ (safetensors ê°•ì œ ì‚¬ìš©)"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ safetensors ê°•ì œ ì‚¬ìš©
            import os
            os.environ['SAFETENSORS_FAST_GPU'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '0'
            os.environ['TORCH_WEIGHTS_ONLY'] = '1'
            os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
            os.environ['TRANSFORMERS_USE_SAFETENSORS'] = '1'
            os.environ['TORCH_WARN_ON_LOAD'] = '0'
            os.environ['TORCH_LOAD_WARN_ONLY'] = '0'
            os.environ['TRANSFORMERS_SAFE_SERIALIZATION'] = '1'
            os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
            
            from sentence_transformers import SentenceTransformer
            
            # safetensorsë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
            self.model = SentenceTransformer(
                self.model_name,
                device=self.device,
                trust_remote_code=True
            )
            
            # ëª¨ë¸ì´ ë¡œë“œëœ í›„ safetensors ì‚¬ìš© í™•ì¸
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            st.info("HuggingFaceEmbeddingsë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            raise e
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            embeddings = self.model.encode(texts, normalize_embeddings=True)
            return embeddings.tolist()
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e
    
    def embed_query(self, text: str) -> List[float]:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            embedding = self.model.encode([text], normalize_embeddings=True)
            return embedding[0].tolist()
        except Exception as e:
            st.error(f"ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {str(e)}")
            raise e

@st.cache_resource
def get_embedding_model():
    """ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ì„ ë°˜í™˜ (safetensors ì§€ì›)"""
    selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
    
    try:
        # ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤ ì‚¬ìš©
        embeddings = SafeSentenceTransformerEmbeddings(
            model_name=selected_embedding,
            device='cpu'
        )
        
        return embeddings
        
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        st.info("HuggingFaceEmbeddingsë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        
        try:
            # HuggingFaceEmbeddingsë¡œ fallback (safetensors ì‚¬ìš©)
            embeddings = HuggingFaceEmbeddings(
                model_name=selected_embedding,
                model_kwargs={
                    'device': 'cpu',
                    'torch_dtype': 'auto',
                    'low_cpu_mem_usage': True,
                    'trust_remote_code': True
                },
                encode_kwargs={'normalize_embeddings': True}
            )
            
            st.success(f"âœ… {selected_embedding} ëª¨ë¸ì„ HuggingFaceEmbeddingsë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return embeddings
            
        except Exception as e2:
            st.error(f"HuggingFaceEmbeddings ì¬ì‹œë„ë„ ì‹¤íŒ¨: {str(e2)}")
            st.error("ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return None

def get_recommended_embedding_model(ai_model_name: str) -> str:
    """AI ëª¨ë¸ì— ë”°ë¥¸ ê¶Œì¥ ì„ë² ë”© ëª¨ë¸ì„ ë°˜í™˜"""
    model_mapping = {
        'hyperclovax': 'jhgan/ko-sroberta-multitask',
        'llama3.2': 'sentence-transformers/all-mpnet-base-v2',
        'llama3.2:3b': 'sentence-transformers/all-MiniLM-L6-v2',
        'llama3.2:8b': 'sentence-transformers/all-mpnet-base-v2',
        'llama3.2:70b': 'intfloat/multilingual-e5-large',
        'mistral': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'mistral:7b': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'mistral:instruct': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'codellama': 'sentence-transformers/all-mpnet-base-v2',
        'codellama:7b': 'sentence-transformers/all-MiniLM-L6-v2',
        'codellama:13b': 'sentence-transformers/all-mpnet-base-v2',
        'codellama:34b': 'intfloat/multilingual-e5-large',
        'gemma': 'sentence-transformers/all-mpnet-base-v2',
        'gemma:2b': 'sentence-transformers/all-MiniLM-L6-v2',
        'gemma:7b': 'sentence-transformers/all-mpnet-base-v2',
        'qwen': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'qwen:7b': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'qwen:14b': 'intfloat/multilingual-e5-large',
        'phi': 'sentence-transformers/all-mpnet-base-v2',
        'phi:2.7b': 'sentence-transformers/all-MiniLM-L6-v2',
        'phi:3.5': 'sentence-transformers/all-mpnet-base-v2',
    }
    # ì •í™• ë§¤ì¹­
    if ai_model_name in model_mapping:
        return model_mapping[ai_model_name]
    # ë¶€ë¶„ ë§¤ì¹­
    for key, value in model_mapping.items():
        if key in ai_model_name.lower():
            return value
    return 'jhgan/ko-sroberta-multitask'

def get_chroma_db_path():
    """ChromaDB ê²½ë¡œ ë°˜í™˜"""
    return "./chroma_db"

def get_model_info_path():
    """ëª¨ë¸ ì •ë³´ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    ai_model = st.session_state.get('selected_model', 'hyperclovax')
    import re
    safe_model = re.sub(r'[^a-zA-Z0-9_\-]', '_', ai_model)
    return f"vector_db_model_info_{safe_model}.json" 

def main():
    st.set_page_config("bizMOB Platform ì±—ë´‡", layout="wide", page_icon="ğŸ“±")

    # ì‚¬ì´ë“œë°”ì— ì œëª©ê³¼ ì„¤ëª…
    st.sidebar.title("ğŸ“± bizMOB Platform ì±—ë´‡")
    st.sidebar.markdown("---")
    st.sidebar.markdown("**ê¸°ëŠ¥**:")
    st.sidebar.markdown("- bizMOB Platform ê°€ì´ë“œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")
    st.sidebar.markdown("- í”Œë«í¼ ì‚¬ìš©ë²• ë° ê¸°ëŠ¥ ì•ˆë‚´")
    st.sidebar.markdown("- ì‹¤ì‹œê°„ ë¬¸ì„œ ì°¸ì¡°")
    st.sidebar.markdown("- **Ollama ì„¤ì¹˜ ëª¨ë¸ ì‚¬ìš©**")
    st.sidebar.markdown("- **íŒŒì¼ ì—…ë¡œë“œ ë° ê´€ë¦¬**")
    
    # Ollama ìƒíƒœ í™•ì¸ ë° ëª¨ë¸ ì„ íƒ
    if check_ollama_models():
        st.sidebar.success("âœ… Ollama ì—°ê²°ë¨")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        available_models = get_ollama_models()
        
        if available_models:
            st.sidebar.markdown("### ğŸ¤– AI ëª¨ë¸ ì„ íƒ")
            
            # ëª¨ë¸ ì„ íƒì„ ìœ„í•œ ë“œë¡­ë‹¤ìš´
            model_options = [f"{model['name']} ({model['size']})" for model in available_models]
            model_names = [model['name'] for model in available_models]
            
            # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
            if 'selected_model' not in st.session_state:
                # ì €ì¥ëœ ëª¨ë¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
                saved_model_info = load_saved_model_info()
                if saved_model_info and saved_model_info.get('ai_model'):
                    saved_ai_model = saved_model_info['ai_model']
                    # ì €ì¥ëœ ëª¨ë¸ì´ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
                    if saved_ai_model in model_names:
                        st.session_state.selected_model = saved_ai_model
                        # ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ë„ ì„¤ì •
                        if saved_model_info.get('embedding_model'):
                            st.session_state.selected_embedding_model = saved_model_info['embedding_model']
                        st.sidebar.success(f"âœ… ì €ì¥ëœ ëª¨ë¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {saved_ai_model}")
                    else:
                        # ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìœ¼ë©´ hyperclovax ë˜ëŠ” ì²« ë²ˆì§¸ ëª¨ë¸
                        default_index = 0
                        for i, name in enumerate(model_names):
                            if 'hyperclovax' in name.lower():
                                default_index = i
                                break
                        st.session_state.selected_model = model_names[default_index]
                else:
                    # ì €ì¥ëœ ì •ë³´ê°€ ì—†ìœ¼ë©´ hyperclovax ë˜ëŠ” ì²« ë²ˆì§¸ ëª¨ë¸
                    default_index = 0
                    for i, name in enumerate(model_names):
                        if 'hyperclovax' in name.lower():
                            default_index = i
                            break
                    st.session_state.selected_model = model_names[default_index]
            
            # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            current_index = 0
            for i, name in enumerate(model_names):
                if name == st.session_state.selected_model:
                    current_index = i
                    break
            
            # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
            selected_index = st.sidebar.selectbox(
                "ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
                options=range(len(model_options)),
                index=current_index,
                format_func=lambda x: model_options[x]
            )
            # ì„ íƒëœ ëª¨ë¸ ì—…ë°ì´íŠ¸
            if selected_index != current_index:
                st.session_state.selected_model = model_names[selected_index]
                recommended_embedding = get_recommended_embedding_model(model_names[selected_index])
                st.session_state.selected_embedding_model = recommended_embedding
                st.sidebar.success(f"âœ… ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤: {model_names[selected_index]}")
                st.sidebar.info(f"ğŸ”¤ ê¶Œì¥ ì„ë² ë”© ëª¨ë¸ë¡œ ìë™ ë³€ê²½: {recommended_embedding}")
                st.session_state['refresh_vector_db_info'] = True
                st.session_state['refresh_faiss_viewer'] = True
                st.session_state['faiss_viewer_page'] = 1  # ëª¨ë¸ ë³€ê²½ ì‹œ í˜ì´ì§€ë„¤ì´ì…˜ ì´ˆê¸°í™”
            
            # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
            selected_model_info = available_models[selected_index]
            st.sidebar.info(f"**í˜„ì¬ ëª¨ë¸**: {selected_model_info['name']}")
            st.sidebar.info(f"**ëª¨ë¸ í¬ê¸°**: {selected_model_info['size']}")
            
        else:
            st.sidebar.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.sidebar.info("Ollamaì— ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    else:
        st.sidebar.error("âŒ Ollama ì—°ê²° ì‹¤íŒ¨")
        st.sidebar.info("Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # ì„ë² ë”© ëª¨ë¸ ìë™ ì…ë ¥ ë° ì •ë³´ í‘œì‹œ (ë“œë¡­ë‹¤ìš´ ì œê±°)
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ì •ë³´")
    
    # ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ AI ëª¨ë¸ì— ë§ëŠ” ê¶Œì¥ ëª¨ë¸ ì‚¬ìš©
    if 'selected_embedding_model' in st.session_state:
        current_embedding = st.session_state.selected_embedding_model
    else:
        current_embedding = get_recommended_embedding_model(st.session_state.selected_model)
        st.session_state.selected_embedding_model = current_embedding
    
    available_embedding_models = get_available_embedding_models()
    selected_embedding_info = available_embedding_models.get(current_embedding, {})
    
    # ì €ì¥ëœ ëª¨ë¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
    saved_model_info = load_saved_model_info()
    if saved_model_info and saved_model_info.get('embedding_model'):
        st.sidebar.success(f"âœ… **ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸**: {selected_embedding_info.get('name', current_embedding)}")
    else:
        st.sidebar.info(f"ğŸ”¤ **ê¶Œì¥ ì„ë² ë”© ëª¨ë¸**: {selected_embedding_info.get('name', current_embedding)}")
    
    st.sidebar.info(f"**ì–¸ì–´**: {selected_embedding_info.get('language', 'Unknown')}")
    st.sidebar.info(f"**í¬ê¸°**: {selected_embedding_info.get('size', 'Unknown')}")
    st.sidebar.caption(f"**ì„¤ëª…**: {selected_embedding_info.get('description', '')}")
    
    # ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    uploaded_files = st.sidebar.file_uploader(
        "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['pdf', 'xlsx', 'xls', 'pptx', 'ppt', 'docx', 'doc'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        key="main_file_uploader"
    )
    
    if uploaded_files:
        st.sidebar.markdown("#### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼")
        
        success_count = 0
        error_count = 0
        
        for uploaded_file in uploaded_files:
            if validate_file_type(uploaded_file.name):
                # íŒŒì¼ ì €ì¥
                saved_path = save_uploaded_file(uploaded_file)
                if saved_path:
                    st.sidebar.success(f"âœ… {uploaded_file.name}")
                    success_count += 1
                else:
                    st.sidebar.error(f"âŒ {uploaded_file.name}")
                    error_count += 1
            else:
                st.sidebar.error(f"âŒ {uploaded_file.name} (ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹)")
                error_count += 1
        
        # ê²°ê³¼ ìš”ì•½
        if success_count > 0:
            st.sidebar.success(f"âœ… {success_count}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì˜µì…˜
            if st.sidebar.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", type="primary", key="main_reinit"):
                if initialize_vector_db_with_documents():
                    st.session_state.vector_db_initialized = True
                    st.sidebar.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì™„ë£Œ!")
                else:
                    st.sidebar.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨")
        
        if error_count > 0:
            st.sidebar.error(f"âŒ {error_count}ê°œ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    left_column, right_column = st.columns([1, 1])
    
    with left_column:
        st.header("ğŸ“± bizMOB Platform ì±—ë´‡")
        st.markdown("PDF_bizMOB_Guide í´ë”ì˜ bizMOB Platform ê°€ì´ë“œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.")
        # ë™ì ìœ¼ë¡œ AI ëª¨ë¸ëª… ì•ˆë‚´
        ai_model_name = st.session_state.get('selected_model', 'hyperclovax')
        if 'hyperclovax' in ai_model_name.lower():
            model_display = 'ë„¤ì´ë²„ HyperCLOVAX ëª¨ë¸'
        else:
            model_display = f"Ollama AI ëª¨ë¸: {ai_model_name}"
        st.info(f"ğŸ’¡ **{model_display}ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF, Excel, PowerPoint, Word ë¬¸ì„œì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.**")
        
        # íƒ­ ìƒì„± (ë²¡í„°DB ìƒì„± íƒ­ì„ ê°€ì¥ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™)
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“– ì±—ë´‡", "ğŸ“‚ íŒŒì¼ ê´€ë¦¬", "ğŸ”— ì†ŒìŠ¤ ê´€ë¦¬", "ğŸ§Š ChromaDB ë·°ì–´", "ğŸ—‚ï¸ ë²¡í„°DB ìƒì„±"])
        
        with tab1:
            # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
            if 'selected_model' in st.session_state:
                # ì €ì¥ëœ ëª¨ë¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
                saved_model_info = load_saved_model_info()
                if saved_model_info and saved_model_info.get('ai_model') == st.session_state.selected_model:
                    st.success(f"ğŸ¤– **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸ (ì €ì¥ë¨)**: {st.session_state.selected_model}")
                else:
                    st.info(f"ğŸ¤– **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸**: {st.session_state.selected_model}")
            
            # í˜„ì¬ ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ ì •ë³´ í‘œì‹œ
            if 'selected_embedding_model' in st.session_state:
                available_embedding_models = get_available_embedding_models()
                selected_embedding_info = available_embedding_models.get(st.session_state.selected_embedding_model, {})
                embedding_name = selected_embedding_info.get('name', st.session_state.selected_embedding_model)
                embedding_language = selected_embedding_info.get('language', 'Unknown')
                
                # ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
                saved_model_info = load_saved_model_info()
                if saved_model_info and saved_model_info.get('embedding_model') == st.session_state.selected_embedding_model:
                    st.success(f"ğŸ”¤ **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸ (ì €ì¥ë¨)**: {embedding_name} ({embedding_language})")
                else:
                    st.info(f"ğŸ”¤ **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸**: {embedding_name} ({embedding_language})")
            
            # ë²¡í„°DB ìƒíƒœ í‘œì‹œ ë° ì´ˆê¸°í™” ë²„íŠ¼
            if check_vector_db_exists():
                st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤ (AI ëª¨ë¸ë³„)")
            else:
                st.warning("âš ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
                if st.button("ğŸ”„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”", type="primary"):
                    if initialize_vector_db_with_documents():
                        st.session_state.vector_db_initialized = True
                        st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            st.markdown("---")
            
            # ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
            def handle_question_submit():
                if st.session_state.get('user_question_input', '').strip():
                    st.session_state['submit_question'] = True

            # ì§ˆë¬¸ ì…ë ¥ + ìš”ì²­ ì•„ì´ì½˜ ë²„íŠ¼ (í•œ ì¤„ì— ë°°ì¹˜) â†’ ì…ë ¥ì°½ë§Œ ë‚¨ê¹€
            user_question = st.text_area(
                "bizMOB Platformì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”",
                placeholder="bizMOB Platformì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                key="user_question_input",
                on_change=handle_question_submit,
                height=80
            )
            
            # ì§ˆë¬¸ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ë³€ê²½ ë˜ëŠ” Enter í‚¤ ì…ë ¥ ì‹œ)
            if (user_question and check_vector_db_exists()) or st.session_state.get('submit_question', False):
                # Enter í‚¤ë¡œ ì œì¶œëœ ê²½ìš° ì²˜ë¦¬ í›„ ìƒíƒœ ì´ˆê¸°í™”
                if st.session_state.get('submit_question', False):
                    st.session_state['submit_question'] = False
                
                with st.spinner("ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
                    response, context = process_question(user_question)
                    
                    if response:
                        st.markdown("### ğŸ¤– AI ë‹µë³€")
                        st.write(response)
                        
                        # ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ
                        if context:
                            st.markdown("### ğŸ“„ ì°¸ì¡° ë¬¸ì„œ")
                            for i, document in enumerate(context):
                                with st.expander(f"ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ {i+1}"):
                                    st.write(document.page_content)
                                    file_name = document.metadata.get('file_name', 'Unknown')
                                    file_type = document.metadata.get('file_type', 'Unknown')
                                    
                                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì°¸ì¡° ì •ë³´ í‘œì‹œ
                                    if file_type == 'PDF':
                                        page_number = document.metadata.get('page', 0) + 1
                                        st.caption(f"ì¶œì²˜: {file_name} (PDF í˜ì´ì§€ {page_number})")
                                        
                                        # PDF í˜ì´ì§€ ë³´ê¸° ë²„íŠ¼
                                        button_key = f"view_page_{file_name}_{page_number}_{i}"
                                        if st.button(f"ğŸ“– PDF í˜ì´ì§€ ë³´ê¸°", key=button_key):
                                            st.session_state.page_number = str(page_number)
                                            st.session_state.pdf_file = file_name
                                            st.session_state.file_type = 'PDF'
                                            
                                    elif file_type == 'Excel':
                                        sheet_name = document.metadata.get('sheet_name', 'Unknown')
                                        st.caption(f"ì¶œì²˜: {file_name} (Excel ì‹œíŠ¸: {sheet_name})")
                                        
                                        # Excel ì‹œíŠ¸ ë³´ê¸° ë²„íŠ¼
                                        button_key = f"view_excel_{file_name}_{sheet_name}_{i}"
                                        if st.button(f"ğŸ“Š Excel ì‹œíŠ¸ ë³´ê¸°", key=button_key):
                                            st.session_state.excel_file = file_name
                                            st.session_state.sheet_name = sheet_name
                                            st.session_state.file_type = 'Excel'
                                            
                                    elif file_type == 'PowerPoint':
                                        slide_number = document.metadata.get('slide_number', 0)
                                        st.caption(f"ì¶œì²˜: {file_name} (PowerPoint ìŠ¬ë¼ì´ë“œ {slide_number})")
                                        
                                        # PowerPoint ìŠ¬ë¼ì´ë“œ ë³´ê¸° ë²„íŠ¼
                                        button_key = f"view_ppt_{file_name}_{slide_number}_{i}"
                                        if st.button(f"ğŸ“½ï¸ PPT ìŠ¬ë¼ì´ë“œ ë³´ê¸°", key=button_key):
                                            st.session_state.ppt_file = file_name
                                            st.session_state.slide_number = str(slide_number)
                                            st.session_state.file_type = 'PowerPoint'
                                            
                                    elif file_type == 'Word':
                                        title = document.metadata.get('title', 'Unknown')
                                        author = document.metadata.get('author', 'Unknown')
                                        st.caption(f"ì¶œì²˜: {file_name} (Word ë¬¸ì„œ: {title}, ì‘ì„±ì: {author})")
                                        
                                        # Word ë¬¸ì„œ ë³´ê¸° ë²„íŠ¼
                                        button_key = f"view_word_{file_name}_{i}"
                                        if st.button(f"ğŸ“„ Word ë¬¸ì„œ ë³´ê¸°", key=button_key):
                                            st.session_state.word_file = file_name
                                            st.session_state.file_type = 'Word'
                                            
                                    else:
                                        st.caption(f"ì¶œì²˜: {file_name}")
                    else:
                        st.error("ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            elif user_question and not check_vector_db_exists():
                st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ˆê¸°í™” ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
        
        with tab2:
            # íŒŒì¼ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤
            manage_uploaded_files()
        
        with tab3:
            st.header("ğŸ”— ì™¸ë¶€ ì†ŒìŠ¤(GitHub) ê´€ë¦¬")
            st.markdown("GitHub ì €ì¥ì†Œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ë©´ ì†ŒìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë²¡í„°DB ìƒì„±ì— í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            github_url = st.text_input("GitHub ì €ì¥ì†Œ URL ì…ë ¥", placeholder="https://github.com/username/repo")
            if st.button("â¬‡ï¸ ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ", key="download_github_btn"):
                if github_url.strip().startswith("https://github.com/"):
                    repo_name = github_url.rstrip('/').split('/')[-1]
                    dest_dir = os.path.join("external_sources", repo_name)
                    os.makedirs("external_sources", exist_ok=True)
                    if os.path.exists(dest_dir):
                        st.info(f"ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì €ì¥ì†Œì…ë‹ˆë‹¤: {dest_dir}")
                    else:
                        with st.spinner("ì €ì¥ì†Œë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                subprocess.run(["git", "clone", github_url, dest_dir], check=True)
                                st.success(f"âœ… ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dest_dir}")
                            except Exception as e:
                                st.error(f"âŒ ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                else:
                    st.error("ì˜¬ë°”ë¥¸ GitHub URLì„ ì…ë ¥í•˜ì„¸ìš”.")
            # ë‹¤ìš´ë¡œë“œëœ ì†ŒìŠ¤ ëª©ë¡ í‘œì‹œ
            if os.path.exists("external_sources"):
                st.markdown("### ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ ì†ŒìŠ¤ ëª©ë¡")
                for repo in os.listdir("external_sources"):
                    repo_path = os.path.join("external_sources", repo)
                    st.write(f"- {repo_path}")

        with tab4:
            st.header("ğŸ§Š ChromaDB ë²¡í„°DB ë·°ì–´")
            # ëª¨ë¸ ë³€ê²½ ì‹œ ë¦¬í”Œë˜ì‹œ
            if st.session_state.get('refresh_chroma_viewer', False):
                st.session_state['refresh_chroma_viewer'] = False
                st.rerun()
            if not check_vector_db_exists():
                st.warning("ë²¡í„°DBê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„°DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")
            else:
                try:
                    vector_store = load_chroma_store()
                    if vector_store:
                        # ChromaDBì—ì„œ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        collection = vector_store._collection
                        count = collection.count()
                        
                        if count > 0:
                            # í˜ì´ì§€ë„¤ì´ì…˜
                            page_size = 100
                            total_pages = max(1, (count + page_size - 1) // page_size)
                            page = st.session_state.get('chroma_viewer_page', 1)
                            if page < 1:
                                page = 1
                            if page > total_pages:
                                page = total_pages
                            
                            # ë¬¸ì„œ ì •ë³´ í‘œì‹œ
                            st.info(f"ì´ {count}ê°œ ë¬¸ì„œê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                            
                            # ìƒ˜í”Œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
                            sample_results = collection.get(limit=min(10, count))
                            if sample_results['documents']:
                                st.markdown("### ğŸ“‹ ì €ì¥ëœ ë¬¸ì„œ ìƒ˜í”Œ")
                                for i, (doc, metadata) in enumerate(zip(sample_results['documents'], sample_results['metadatas'])):
                                    with st.expander(f"ë¬¸ì„œ {i+1}"):
                                        st.write(f"**ë‚´ìš©**: {doc[:200]}...")
                                        st.write(f"**ë©”íƒ€ë°ì´í„°**: {metadata}")
                            
                            # í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜
                            col_prev, col_page, col_next = st.columns([1,2,1])
                            with col_prev:
                                if st.button("â¬…ï¸ ì´ì „", key="chroma_prev"):
                                    if page > 1:
                                        st.session_state['chroma_viewer_page'] = page - 1
                                        st.rerun()
                            with col_page:
                                st.markdown(f"<div style='text-align:center;'>í˜ì´ì§€ {page} / {total_pages}</div>", unsafe_allow_html=True)
                            with col_next:
                                if st.button("ë‹¤ìŒ â¡ï¸", key="chroma_next"):
                                    if page < total_pages:
                                        st.session_state['chroma_viewer_page'] = page + 1
                                        st.rerun()
                        else:
                            st.info("ë²¡í„°DBì— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ChromaDBë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ChromaDB ë²¡í„°DBë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")

        with tab5:
            st.header("ğŸ—‚ï¸ ë²¡í„°DB ìƒì„±/ì´ˆê¸°í™”")
            # ëª¨ë¸ ë³€ê²½ ì‹œ ë¦¬í”Œë˜ì‹œ
            if st.session_state.get('refresh_vector_db_info', False):
                st.session_state['refresh_vector_db_info'] = False
                st.rerun()
            st.markdown("ë¬¸ì„œ ì—…ë¡œë“œ í›„, ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.info("ë²¡í„°DBëŠ” PDF, Excel, PowerPoint, Word ë¬¸ì„œì˜ ë‚´ìš©ì„ ì„ë² ë”©í•˜ì—¬ ê²€ìƒ‰ì„ ë¹ ë¥´ê²Œ í•´ì¤ë‹ˆë‹¤.")
            # ë²¡í„°DB ìƒíƒœ
            if check_vector_db_exists():
                st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            # ë²¡í„°DB ìƒì„±/ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ğŸ—‚ï¸ ë²¡í„°DB ìƒì„±/ì´ˆê¸°í™”", type="primary", key="vector_db_create_btn"):
                with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    result = initialize_vector_db_with_documents()
                if result:
                    st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±/ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("âŒ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±/ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            # ë²¡í„°DB ì •ë³´ í‘œì‹œ (ëª¨ë¸ë³„)
            model_info = load_saved_model_info()
            st.markdown("---")
            st.markdown(f"### í˜„ì¬ ì„ íƒëœ AI ëª¨ë¸ ì •ë³´")
            if model_info:
                st.markdown(f"**AI ëª¨ë¸:** {model_info.get('ai_model', '-')}")
                st.markdown(f"**ì„ë² ë”© ëª¨ë¸:** {model_info.get('embedding_model', '-')}")
                st.markdown(f"**ìƒì„± ì‹œê°:** {model_info.get('timestamp', '-')}")
            else:
                st.info("ì´ ëª¨ë¸ë¡œ ìƒì„±ëœ ë²¡í„°DB ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë²¡í„°DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main() 