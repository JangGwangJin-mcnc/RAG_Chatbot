#!/usr/bin/env python3
"""
bizMOB ì±—ë´‡ - ChromaDB ì „ìš© ë²„ì „
bizmob_chatbot_original.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ChromaDBë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„
"""

import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile
import os
import sys
import json
import pandas as pd
import re
import logging
import glob
import shutil
import subprocess
import time
import warnings
from datetime import datetime
from typing import List, Dict, Any, Optional
import fitz  # PyMuPDF
from pptx import Presentation
from docx import Document as DocxDocument
from safetensors.torch import load_file
import sentence_transformers
import html

# ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - safetensors ê°•ì œ ì‚¬ìš©
os.environ['TORCH_WARN_ON_LOAD'] = '0'
os.environ['TORCH_LOAD_WARN_ONLY'] = '0'
os.environ['PYTORCH_DISABLE_WARNINGS'] = '1'
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ['SAFETENSORS_FAST_GPU'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '0'
os.environ['TORCH_WEIGHTS_ONLY'] = '1'
os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
os.environ['TRANSFORMERS_USE_SAFETENSORS'] = '1'
# ì¶”ê°€ safetensors ê°•ì œ ì„¤ì •
os.environ['SAFETENSORS_FAST_GPU'] = '1'
os.environ['TRANSFORMERS_SAFE_SERIALIZATION'] = '1'
os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
os.environ['TRANSFORMERS_CACHE'] = './model_cache'
os.environ['HF_HOME'] = './huggingface'
os.environ['TORCH_HOME'] = './torch_cache'

# ì™¸ë¶€ ì†ŒìŠ¤ í™•ì¥ì ë¦¬ìŠ¤íŠ¸ ìƒìˆ˜ ì„ ì–¸
EXTERNAL_SOURCE_EXTS = [
    ".py", ".js", ".scss", ".ts", ".vue", ".md", ".txt", ".rst", ".json", ".yaml", ".yml"
]

# ì „ì—­ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ë³€ìˆ˜
HYBRID_SEARCH_CONFIG = {
    'bm25_weight': 0.3,
    'vector_weight': 0.7,
    'initial_k': 8,
    'final_k': 3,
    'enable_reranking': True,
    'metadata_boost': True,
    'recency_boost': True
}

# ChromaDB ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    import chromadb
    from langchain_community.vectorstores import Chroma
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install chromadbë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    log_dir = os.path.join(current_dir, "logs")
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    try:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, f"bizmob_chatbot_{datetime.now().strftime('%Y%m%d')}.log")
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (UTF-8 ì¸ì½”ë”©)
        file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
        
        # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        print(f"ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_file}")
        
    except (PermissionError, OSError) as e:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ì‹œ ì½˜ì†” ë¡œê¹…ë§Œ ì‚¬ìš©
        print(f"ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}. ì½˜ì†” ë¡œê¹…ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ (í•­ìƒ ì¶”ê°€)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    return logger

# ë¡œê±° ì´ˆê¸°í™”
logger = setup_logging()

# UI ì»´í¬ë„ŒíŠ¸ ëª¨ë“ˆ import
from ui_components import (
    apply_css_styles, setup_page_config,
    show_model_selector,
    show_embedding_model_info,
    show_admin_interface
)

# PyTorch ìŠ¤ë ˆë“œ ì„¤ì • (ì„±ëŠ¥ ìµœì í™”)
try:
    import torch
    torch.set_num_threads(1)
except Exception as e:
    logger.warning(f"PyTorch thread setup failed: {e}")

# ê¸°íƒ€ í•„ìš”í•œ importë“¤
try:
    from langchain_core.documents.base import Document
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.prompts import PromptTemplate
    from langchain_core.runnables import Runnable, RunnablePassthrough
    from langchain.schema.output_parser import StrOutputParser
    from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredExcelLoader, UnstructuredPowerPointLoader, UnstructuredWordDocumentLoader
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_ollama import OllamaLLM
    from langchain_community.llms import Ollama
    from langchain.chains import RetrievalQA
    from langchain.retrievers import ParentDocumentRetriever
    from langchain.storage import InMemoryStore
    from langchain_core.embeddings import Embeddings
    from langchain_community.retrievers import BM25Retriever
    from langchain.retrievers import EnsembleRetriever
    from langchain.retrievers import ContextualCompressionRetriever
    from langchain.retrievers.document_compressors import LLMChainExtractor
except ImportError as e:
    st.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    st.stop()

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv, dotenv_values
load_dotenv()

# UI ìŠ¤íƒ€ì¼ ë° í˜ì´ì§€ ì„¤ì • ì ìš©
apply_css_styles()
setup_page_config()



############################### 1ë‹¨ê³„ : íŒŒì¼ ì—…ë¡œë“œ ë° ê´€ë¦¬ í•¨ìˆ˜ë“¤ ##########################

def save_uploaded_file(uploaded_file: UploadedFile, folder_path: str = "PDF_bizMOB_Guide") -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì§€ì •ëœ í´ë”ì— ì €ì¥í•˜ê³  íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜"""
    try:
        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        file_path = os.path.join(folder_path, uploaded_file.name)
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        return file_path
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def get_supported_file_types() -> dict:
    """ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ê³¼ ì„¤ëª…ì„ ë°˜í™˜"""
    return {
        'pdf': 'PDF ë¬¸ì„œ (.pdf)',
        'xlsx': 'Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸ (.xlsx)',
        'xls': 'Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸ (.xls)',
        'pptx': 'PowerPoint í”„ë ˆì  í…Œì´ì…˜ (.pptx)',
        'ppt': 'PowerPoint í”„ë ˆì  í…Œì´ì…˜ (.ppt)',
        'docx': 'Word ë¬¸ì„œ (.docx)',
        'doc': 'Word ë¬¸ì„œ (.doc)'
    }

def validate_file_type(filename: str) -> bool:
    """íŒŒì¼ í˜•ì‹ì´ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸"""
    supported_extensions = ['.pdf', '.xlsx', '.xls', '.pptx', '.ppt', '.docx', '.doc']
    file_ext = os.path.splitext(filename.lower())[1]
    return file_ext in supported_extensions

def upload_and_process_files() -> bool:
    """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ í•¨ìˆ˜"""
    st.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
    
    # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['pdf', 'xlsx', 'xls', 'pptx', 'ppt', 'docx', 'doc'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_files:
        st.markdown("#### ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
        
        success_count = 0
        error_count = 0
        
        for uploaded_file in uploaded_files:
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"ğŸ“„ {uploaded_file.name}")
            
            with col2:
                file_size = len(uploaded_file.getbuffer()) / 1024  # KB
                st.write(f"{file_size:.1f} KB")
            
            with col3:
                if validate_file_type(uploaded_file.name):
                    # íŒŒì¼ ì €ì¥
                    saved_path = save_uploaded_file(uploaded_file)
                    if saved_path:
                        st.success("âœ…")
                        success_count += 1
                    else:
                        st.error("âŒ")
                        error_count += 1
                else:
                    st.error("âŒ")
                    error_count += 1
        
        # ê²°ê³¼ ìš”ì•½
        if success_count > 0:
            st.success(f"âœ… {success_count}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì˜µì…˜
            if st.button("ğŸ”„ ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™”", type="primary"):
                if initialize_vector_db_with_documents():
                    st.session_state.vector_db_initialized = True
                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ìƒˆë¡œìš´ íŒŒì¼ë“¤ë¡œ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                else:
                    st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        if error_count > 0:
            st.error(f"âŒ {error_count}ê°œ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return success_count > 0
    
    return False

def list_uploaded_files(folder_path: str = "PDF_bizMOB_Guide") -> dict:
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ í˜•ì‹ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ë°˜í™˜"""
    if not os.path.exists(folder_path):
        return {}
    
    files_by_type = {
        'PDF': [],
        'Excel': [],
        'PowerPoint': [],
        'Word': []
    }
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = {
        '*.pdf': 'PDF',
        '*.xlsx': 'Excel',
        '*.xls': 'Excel',
        '*.pptx': 'PowerPoint',
        '*.ppt': 'PowerPoint',
        '*.docx': 'Word',
        '*.doc': 'Word'
    }
    
    for pattern, file_type in supported_extensions.items():
        files = glob.glob(os.path.join(folder_path, pattern))
        for file_path in files:
            file_size = os.path.getsize(file_path) / 1024  # KB
            files_by_type[file_type].append({
                'name': os.path.basename(file_path),
                'path': file_path,
                'size': file_size
            })
    
    return files_by_type

def safe_key(filename: str) -> str:
    """íŒŒì¼ëª…ì„ ì•ˆì „í•œ session state í‚¤ë¡œ ë³€í™˜"""
    # íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜
    safe_name = re.sub(r'[^a-zA-Z0-9_]', '_', filename)
    # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•Šë„ë¡ prefix ì¶”ê°€
    if safe_name and safe_name[0].isdigit():
        safe_name = 'file_' + safe_name
    return safe_name

def delete_file(file_path: str) -> bool:
    """íŒŒì¼ ì‚­ì œ í•¨ìˆ˜"""
    try:
        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(file_path):
            st.error(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return False
        
        # íŒŒì¼ ì‚­ì œ
        os.remove(file_path)
        
        # ì‚­ì œ í™•ì¸
        if os.path.exists(file_path):
            st.error(f"íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {file_path}")
            return False
        
        return True
    except PermissionError:
        st.error(f"íŒŒì¼ ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    except Exception as e:
        st.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def delete_file_with_confirmation(file_path: str, file_name: str) -> bool:
    """í™•ì¸ í›„ íŒŒì¼ ì‚­ì œ í•¨ìˆ˜"""
    # ì‚­ì œ í™•ì¸ì„ ìœ„í•œ session state í‚¤
    confirm_key = f"confirm_delete_{file_name}"
    
    if confirm_key not in st.session_state:
        st.session_state[confirm_key] = False
    
    if not st.session_state[confirm_key]:
        # ì‚­ì œ í™•ì¸ ë²„íŠ¼
        if st.button(f"ğŸ—‘ï¸ ì‚­ì œ í™•ì¸", key=f"confirm_{file_name}"):
            st.session_state[confirm_key] = True
            return False
        return False
    else:
        # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
        if delete_file(file_path):
            st.success(f"âœ… {file_name} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            # session state ì •ë¦¬
            del st.session_state[confirm_key]
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì œì•ˆ
            st.warning("âš ï¸ ì‚­ì œëœ íŒŒì¼ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜ë˜ë ¤ë©´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", key=f"reinit_after_delete_{file_name}"):
                if initialize_vector_db():
                    st.session_state.vector_db_initialized = True
                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        else:
            st.error(f"âŒ {file_name} íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            # session state ì •ë¦¬
            del st.session_state[confirm_key]
            return False

def manage_uploaded_files() -> None:
    """ì—…ë¡œë“œëœ íŒŒì¼ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤"""
    st.markdown("### ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼ ê´€ë¦¬")
    
    # ì‹ ê·œ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
    with st.expander("ğŸ“ ì‹ ê·œ íŒŒì¼ ì—…ë¡œë“œ", expanded=False):
        st.markdown("#### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        st.markdown("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
        
        # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
        uploaded_files = st.file_uploader(
            "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['pdf', 'xlsx', 'xls', 'pptx', 'ppt', 'docx', 'doc'],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="file_manager_uploader"
        )
        
        if uploaded_files:
            st.markdown("#### ğŸ“‹ ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡")
            
            success_count = 0
            error_count = 0
            
            for uploaded_file in uploaded_files:
                col1, col2, col3 = st.columns([3, 1, 1])
                
                with col1:
                    st.write(f"ğŸ“„ {uploaded_file.name}")
                
                with col2:
                    file_size = len(uploaded_file.getbuffer()) / 1024  # KB
                    st.write(f"{file_size:.1f} KB")
                
                with col3:
                    if validate_file_type(uploaded_file.name):
                        # íŒŒì¼ ì €ì¥
                        saved_path = save_uploaded_file(uploaded_file)
                        if saved_path:
                            st.success("âœ…")
                            success_count += 1
                        else:
                            st.error("âŒ")
                            error_count += 1
                    else:
                        st.error("âŒ")
                        error_count += 1
            
            # ê²°ê³¼ ìš”ì•½
            if success_count > 0:
                st.success(f"âœ… {success_count}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™” ì˜µì…˜
                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", type="primary", key="file_manager_reinit"):
                        if initialize_vector_db_with_documents():
                            st.session_state.vector_db_initialized = True
                            st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                with col2:
                    if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨", key="file_manager_refresh"):
                        pass  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ì€ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìˆ˜í–‰
            
            if error_count > 0:
                st.error(f"âŒ {error_count}ê°œ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    files_by_type = list_uploaded_files()
    
    if not any(files_by_type.values()):
        st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.markdown("### ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹")
        st.markdown("- **PDF** (.pdf): ë§¤ë‰´ì–¼, ê°€ì´ë“œ ë¬¸ì„œ")
        st.markdown("- **Excel** (.xlsx, .xls): ë°ì´í„° ì‹œíŠ¸, ë¶„ì„ ìë£Œ")
        st.markdown("- **PowerPoint** (.pptx, .ppt): í”„ë ˆì  í…Œì´ì…˜, êµìœ¡ ìë£Œ")
        st.markdown("- **Word** (.docx, .doc): ë³´ê³ ì„œ, ë¬¸ì„œ, ë§¤ë‰´ì–¼")
        return
    
    # íŒŒì¼ í†µê³„ ì •ë³´
    total_files = sum(len(files) for files in files_by_type.values())
    total_size = sum(sum(file_info['size'] for file_info in files) for files in files_by_type.values())
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“ ì´ íŒŒì¼ ìˆ˜", f"{total_files}ê°œ")
    with col2:
        st.metric("ğŸ’¾ ì´ ìš©ëŸ‰", f"{total_size:.1f} KB")
    with col3:
        if check_vector_db_exists():
            st.success("âœ… ë²¡í„°DB ì¤€ë¹„ë¨")
        else:
            st.warning("âš ï¸ ë²¡í„°DB ë¯¸ì¤€ë¹„")
    
    # ë²¡í„°DB ì¬ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì´ˆê¸°í™”", type="primary", key="file_manager_main_reinit"):
        if initialize_vector_db_with_documents():
            st.session_state.vector_db_initialized = True
            st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # íŒŒì¼ í˜•ì‹ë³„ë¡œ íƒ­ ìƒì„± (ìˆ˜ì •)
    file_types_with_files = [(file_type, files) for file_type, files in files_by_type.items() if files]
    tab_names = [f"{file_type} ({len(files)})" for file_type, files in file_types_with_files]
    if tab_names:
        tabs = st.tabs(tab_names)
        for i, (file_type, files) in enumerate(file_types_with_files):
            with tabs[i]:
                st.markdown(f"#### {file_type} íŒŒì¼ ëª©ë¡")
                
                for file_info in files:
                    with st.expander(f"ğŸ“„ {file_info['name']} ({file_info['size']:.1f} KB)"):
                        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                        
                        with col1:
                            st.write(f"**íŒŒì¼ëª…:** {file_info['name']}")
                            st.write(f"**í¬ê¸°:** {file_info['size']:.1f} KB")
                            st.write(f"**ê²½ë¡œ:** {file_info['path']}")
                        
                        with col2:
                            # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            safe_download_key = safe_key(file_info['name'])
                            with open(file_info['path'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                                    data=f.read(),
                                    file_name=file_info['name'],
                                    key=f"download_{safe_download_key}"
                                )
                        
                        with col3:
                            # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼
                            safe_preview_key = safe_key(file_info['name'])
                            if st.button("ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°", key=f"preview_{safe_preview_key}"):
                                st.session_state.preview_file = file_info['path']
                                st.session_state.preview_file_type = file_type
                                st.session_state.preview_file_name = file_info['name']
                        
                        with col4:
                            # íŒŒì¼ ì‚­ì œ ë²„íŠ¼ - ì•ˆì „í•œ í‚¤ ì‚¬ìš©
                            safe_file_key = safe_key(file_info['name'])
                            delete_key = f"delete_{safe_file_key}"
                            
                            if delete_key not in st.session_state:
                                st.session_state[delete_key] = False
                            
                            if not st.session_state[delete_key]:
                                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"btn_{safe_file_key}"):
                                    st.session_state[delete_key] = True
                            else:
                                st.warning(f"ì •ë§ë¡œ '{file_info['name']}' íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                                col_confirm1, col_confirm2 = st.columns(2)
                                with col_confirm1:
                                    if st.button("âœ… í™•ì¸", key=f"confirm_{safe_file_key}"):
                                        if delete_file(file_info['path']):
                                            st.success(f"âœ… {file_info['name']} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                            # ë²¡í„°DB ì¬ì´ˆê¸°í™” ì œì•ˆ
                                            st.warning("âš ï¸ ì‚­ì œëœ íŒŒì¼ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜ë˜ë ¤ë©´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                                            if st.button("ğŸ”„ ë²¡í„°DB ì¬ì´ˆê¸°í™”", key=f"reinit_{safe_file_key}"):
                                                if initialize_vector_db_with_documents():
                                                    st.session_state.vector_db_initialized = True
                                                    st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                            # session state ì •ë¦¬
                                            del st.session_state[delete_key]
                                        else:
                                            st.error(f"âŒ {file_info['name']} íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                            del st.session_state[delete_key]
                                with col_confirm2:
                                    if st.button("âŒ ì·¨ì†Œ", key=f"cancel_{safe_file_key}"):
                                        del st.session_state[delete_key]
                    
                    # íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜
                    if 'preview_file' in st.session_state and st.session_state.preview_file_type == file_type:
                        st.markdown("---")
                        st.markdown(f"#### ğŸ‘ï¸ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°: {st.session_state.preview_file_name}")
                        
                        try:
                            if file_type == 'PDF':
                                # PDF ë¯¸ë¦¬ë³´ê¸°
                                images = convert_pdf_to_images(st.session_state.preview_file)
                                if images:
                                    st.image(images[0], caption="ì²« í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°", width=400)
                                    st.info(f"ì´ {len(images)}í˜ì´ì§€")
                            
                            elif file_type == 'Excel':
                                # Excel ë¯¸ë¦¬ë³´ê¸°
                                excel_file = pd.ExcelFile(st.session_state.preview_file)
                                sheet_names = excel_file.sheet_names
                                st.write(f"**ì‹œíŠ¸ ëª©ë¡:** {', '.join(sheet_names)}")
                                
                                if sheet_names:
                                    selected_sheet = st.selectbox("ì‹œíŠ¸ ì„ íƒ", sheet_names)
                                    df = pd.read_excel(st.session_state.preview_file, sheet_name=selected_sheet)
                                    st.dataframe(df.head(10), use_container_width=True)
                                    st.info(f"ì´ {len(df)}í–‰, {len(df.columns)}ì—´")
                            
                            elif file_type == 'PowerPoint':
                                # PowerPoint ë¯¸ë¦¬ë³´ê¸°
                                prs = Presentation(st.session_state.preview_file)
                                st.write(f"**ì´ ìŠ¬ë¼ì´ë“œ ìˆ˜:** {len(prs.slides)}")
                                
                                if prs.slides:
                                    slide_content = ""
                                    for i, slide in enumerate(prs.slides[:3]):  # ì²˜ìŒ 3ê°œ ìŠ¬ë¼ì´ë“œë§Œ
                                        slide_content += f"**ìŠ¬ë¼ì´ë“œ {i+1}:**\n"
                                        for shape in slide.shapes:
                                            if hasattr(shape, "text") and shape.text.strip():
                                                slide_content += f"{shape.text}\n"
                                        slide_content += "\n"
                                    
                                    st.text_area("ìŠ¬ë¼ì´ë“œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", slide_content, height=200)
                            
                            elif file_type == 'Word':
                                # Word ë¯¸ë¦¬ë³´ê¸°
                                doc = DocxDocument(st.session_state.preview_file)
                                st.write(f"**ì œëª©:** {doc.core_properties.title or 'ì œëª© ì—†ìŒ'}")
                                st.write(f"**ì‘ì„±ì:** {doc.core_properties.author or 'ì‘ì„±ì ì—†ìŒ'}")
                                
                                # ì²˜ìŒ ëª‡ ë‹¨ë½ë§Œ ë¯¸ë¦¬ë³´ê¸°
                                preview_text = ""
                                for para in doc.paragraphs[:10]:
                                    if para.text.strip():
                                        preview_text += para.text + "\n\n"
                                
                                st.text_area("ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", preview_text, height=200)
                        
                        except Exception as e:
                            st.error(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        
                        # ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸° ë²„íŠ¼
                        if st.button("âŒ ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸°"):
                            del st.session_state.preview_file
                            del st.session_state.preview_file_type
                            del st.session_state.preview_file_name 

############################### 1ë‹¨ê³„ : PDF ë¬¸ì„œë¥¼ ë²¡í„°DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë“¤ ##########################

## 1: PDF_bizMOB_Guide í´ë”ì—ì„œ ëª¨ë“  ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì•„ì„œ Documentë¡œ ë³€í™˜
def load_all_documents_from_folder(folder_path: str = "PDF_bizMOB_Guide") -> List[Document]:
    documents = []
    
    if not os.path.exists(folder_path):
        st.error(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return documents
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = {
        '*.pdf': 'PDF',
        '*.xlsx': 'Excel',
        '*.xls': 'Excel',
        '*.pptx': 'PowerPoint',
        '*.ppt': 'PowerPoint',
        '*.docx': 'Word',
        '*.doc': 'Word'
    }
    
    all_files = []
    for pattern, file_type in supported_extensions.items():
        files = glob.glob(os.path.join(folder_path, pattern))
        all_files.extend([(f, file_type) for f in files])
    
    if not all_files:
        st.warning(f"{folder_path} í´ë”ì— ì§€ì›í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ì§€ì› í˜•ì‹: PDF, Excel (.xlsx, .xls), PowerPoint (.pptx, .ppt), Word (.docx, .doc)")
        return documents
    
    for file_path, file_type in all_files:
        try:
            st.info(f"{file_type} íŒŒì¼ ë¡œë”© ì¤‘: {os.path.basename(file_path)}")
            
            if file_type == 'PDF':
                loader = PyMuPDFLoader(file_path)
                doc = loader.load()
            elif file_type == 'Excel':
                doc = load_excel_file(file_path)
            elif file_type == 'PowerPoint':
                doc = load_powerpoint_file(file_path)
            elif file_type == 'Word':
                doc = load_word_file(file_path)
            
            for d in doc:
                d.metadata['file_path'] = file_path
                d.metadata['file_name'] = os.path.basename(file_path)
                d.metadata['file_type'] = file_type
            
            documents.extend(doc)
            st.success(f"âœ… {os.path.basename(file_path)} ({file_type}) ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            st.error(f"âŒ {os.path.basename(file_path)} ({file_type}) ë¡œë”© ì‹¤íŒ¨: {str(e)}")
    
    # ì™¸ë¶€ ì†ŒìŠ¤ ì½”ë“œ(.py, .md ë“±)ë„ í¬í•¨
    ext_src_dir = "external_sources"
    if os.path.exists(ext_src_dir):
        for repo in os.listdir(ext_src_dir):
            repo_path = os.path.join(ext_src_dir, repo)
            for ext in EXTERNAL_SOURCE_EXTS:
                for file in glob.glob(f"{repo_path}/**/*{ext}", recursive=True):
                    try:
                        if os.path.getsize(file) > 2*1024*1024:
                            st.warning(f"{file} íŒŒì¼ì€ 2MBë¥¼ ì´ˆê³¼í•˜ì—¬ ë²¡í„°DBì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            continue
                        with open(file, "r", encoding="utf-8", errors="ignore") as f:
                            content = f.read()
                        doc = Document(
                            page_content=content,
                            metadata={
                                'file_path': file,
                                'file_name': os.path.basename(file),
                                'file_type': 'Source',
                                'repo': repo
                            }
                        )
                        documents.append(doc)
                    except Exception as e:
                        st.warning(f"{file} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return documents

def load_excel_file(file_path: str) -> List[Document]:
    """Excel íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # Excel íŒŒì¼ ì½ê¸°
        excel_file = pd.ExcelFile(file_path)
        
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            # ë°ì´í„°í”„ë ˆì„ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            text_content = f"ì‹œíŠ¸ëª…: {sheet_name}\n\n"
            
            # í—¤ë” ì •ë³´ ì¶”ê°€
            if not df.empty:
                text_content += f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}\n\n"
                
                # ë°ì´í„° ë‚´ìš© ì¶”ê°€ (ì²˜ìŒ 100í–‰ê¹Œì§€ë§Œ)
                for idx, row in df.head(100).iterrows():
                    row_text = " | ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
                    if row_text.strip():
                        text_content += f"í–‰ {idx+1}: {row_text}\n"
            
            # Document ìƒì„±
            doc = Document(
                page_content=text_content,
                metadata={
                    'file_path': file_path,
                    'file_name': os.path.basename(file_path),
                    'file_type': 'Excel',
                    'sheet_name': sheet_name
                }
            )
            documents.append(doc)
            
    except Exception as e:
        st.error(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

def load_powerpoint_file(file_path: str) -> List[Document]:
    """PowerPoint íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # PowerPoint íŒŒì¼ ì½ê¸°
        prs = Presentation(file_path)
        
        for slide_num, slide in enumerate(prs.slides, 1):
            text_content = f"ìŠ¬ë¼ì´ë“œ {slide_num}:\n\n"
            
            # ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    text_content += f"{shape.text}\n\n"
            
            # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ Document ìƒì„±
            if text_content.strip() and text_content != f"ìŠ¬ë¼ì´ë“œ {slide_num}:\n\n":
                doc = Document(
                    page_content=text_content,
                    metadata={
                        'file_path': file_path,
                        'file_name': os.path.basename(file_path),
                        'file_type': 'PowerPoint',
                        'slide_number': slide_num
                    }
                )
                documents.append(doc)
                
    except Exception as e:
        st.error(f"PowerPoint íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

def load_word_file(file_path: str) -> List[Document]:
    """Word íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    documents = []
    try:
        # Word íŒŒì¼ ì½ê¸°
        doc = DocxDocument(file_path)
        
        # ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ Documentë¡œ ì²˜ë¦¬
        text_content = ""
        
        # ì œëª© ì •ë³´ ì¶”ê°€
        if doc.core_properties.title:
            text_content += f"ì œëª©: {doc.core_properties.title}\n\n"
        
        # ë‹¨ë½ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for para in doc.paragraphs:
            if para.text.strip():
                text_content += para.text + "\n\n"
        
        # í‘œ ë‚´ìš© ì¶”ì¶œ
        for table in doc.tables:
            text_content += "í‘œ ë‚´ìš©:\n"
            for row in table.rows:
                row_text = " | ".join([cell.text for cell in row.cells if cell.text.strip()])
                if row_text.strip():
                    text_content += row_text + "\n"
            text_content += "\n"
        
        # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ Document ìƒì„±
        if text_content.strip():
            doc_chunk = Document(
                page_content=text_content,
                metadata={
                    'file_path': file_path,
                    'file_name': os.path.basename(file_path),
                    'file_type': 'Word',
                    'title': doc.core_properties.title or 'Unknown',
                    'author': doc.core_properties.author or 'Unknown'
                }
            )
            documents.append(doc_chunk)
            
    except Exception as e:
        st.error(f"Word íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return documents

## 2: Documentë¥¼ ë” ì‘ì€ documentë¡œ ë³€í™˜
def chunk_documents(documents: List[Document]) -> List[Document]:
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    return text_splitter.split_documents(documents)

## 3: Documentë¥¼ ë²¡í„°DBë¡œ ì €ì¥ (ChromaDB ì‚¬ìš©)
def save_to_vector_store(documents: List[Document]) -> None:
    try:
        # ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = get_embedding_model()
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        
        st.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {selected_embedding}")
        
        # ChromaDBì— ì €ì¥
        save_to_chroma_store(documents)
        st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ (ChromaDB ì‚¬ìš©)")
    except Exception as e:
        st.error(f"âŒ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

## 4: ë²¡í„°DB ì´ˆê¸°í™” í•¨ìˆ˜ (ë¬¸ì„œ ë¡œë”© í¬í•¨)
def initialize_vector_db_with_documents():
    """PDF_bizMOB_Guide í´ë”ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„°DBë¥¼ ì´ˆê¸°í™”"""
    with st.spinner("bizMOB Platform ê°€ì´ë“œ ë¬¸ì„œë“¤ì„ ë¡œë”©í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
        # ëª¨ë“  ë¬¸ì„œë“¤ ë¡œë“œ (PDF, Excel, PowerPoint)
        documents = load_all_documents_from_folder()
        
        if not documents:
            st.error("ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ë¬¸ì„œ ì²­í‚¹
        st.info("ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ì¤‘...")
        chunked_documents = chunk_documents(documents)
        st.success(f"âœ… {len(chunked_documents)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")
        
        # ë²¡í„°DB ì €ì¥
        st.info("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì¤‘...")
        save_to_chroma_store(chunked_documents)
        
        # ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥
        try:
            model_info = {
                'ai_model': st.session_state.get('selected_model', 'exaone3.5'),
                'embedding_model': st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask'),
                'timestamp': pd.Timestamp.now().isoformat()
            }
            
            import json
            with open('vector_db_model_info.json', 'w', encoding='utf-8') as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            
            st.success("âœ… ëª¨ë¸ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ ëª¨ë¸ ì •ë³´ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return True

## 4-1: ë²¡í„°DB ì´ˆê¸°í™” í•¨ìˆ˜ (ChromaDBë§Œ ì´ˆê¸°í™”)
def initialize_vector_db():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    logger.info("Vector database initialization started")
    
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return False
    
    try:
        # ChromaDB ë””ë ‰í† ë¦¬ ìƒì„±
        chroma_path = get_chroma_db_path()
        logger.info(f"ChromaDB path: {chroma_path}")
        os.makedirs(chroma_path, exist_ok=True)
        logger.info("ChromaDB directory created successfully")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        import chromadb
        import time
        
        # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œë„
        max_retries = 3
        client = None
        
        for attempt in range(max_retries):
            try:
                client = chromadb.PersistentClient(
                    path=chroma_path,
                    settings=chromadb.config.Settings(
                        allow_reset=True,
                        anonymized_telemetry=False
                    )
                )
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"Client connection attempt {attempt + 1} failed: {e}")
                    time.sleep(1)
                else:
                    raise e
        
        if client is None:
            raise Exception("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
        
        collection_name = "bizmob_documents"
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
        try:
            client.delete_collection(name=collection_name)
            logger.info("Existing collection deleted")
            time.sleep(0.5)  # ì ì‹œ ëŒ€ê¸°
        except:
            logger.info("No existing collection to delete")
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        collection = client.create_collection(name=collection_name)
        logger.info("New collection created")
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        model_info = {
            'ai_model': st.session_state.get('selected_model', 'exaone3.5'),
            'embedding_model': st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask'),
            'timestamp': pd.Timestamp.now().isoformat()
        }
        logger.info(f"Model info: {model_info}")
        
        model_info_path = get_model_info_path()
        logger.info(f"Model info file path: {model_info_path}")
        
        with open(model_info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        st.session_state.vector_db_initialized = True
        st.success("âœ… ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("Vector database initialization successful")
        return True
        
    except Exception as e:
        error_msg = f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
        logger.error(f"Vector database initialization failed: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")
        return False

def save_to_chroma_store(documents: list) -> None:
    """ë¬¸ì„œë¥¼ ChromaDBì— ì €ì¥"""
    logger.info(f"Vector database save started - document count: {len(documents)}")
    
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return
    
    try:
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        import os
        os.environ['TOKENIZERS_PARALLELISM'] = 'false'
        os.environ['PYTORCH_DISABLE_WARNINGS'] = '1'
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        logger.info(f"Loading embedding model: {selected_embedding}")
        
        try:
            # SafeSentenceTransformerEmbeddings ì‚¬ìš© (torch.load ì·¨ì•½ì  ë°©ì§€)
            embeddings = SafeSentenceTransformerEmbeddings(
                model_name=selected_embedding,
                device='cpu'
            )
            logger.info("Embedding model loaded successfully")
        except Exception as e:
            logger.error(f"Embedding model loading failed: {e}")
            st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            st.info("ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            return
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì§€ì†ì  ì €ì¥ì„ ìœ„í•´ ê²½ë¡œ ì§€ì •)
        try:
            import chromadb
            import time
            chroma_path = get_chroma_db_path()
            os.makedirs(chroma_path, exist_ok=True)
            
            # session_stateì—ì„œ ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í™•ì¸
            if 'chroma_client' in st.session_state:
                try:
                    # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í•´ì œ ì‹œë„
                    del st.session_state.chroma_client
                    import gc
                    gc.collect()
                    time.sleep(0.5)
                except:
                    pass
            
            # ì§€ì†ì  ì €ì¥ì„ ìœ„í•œ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì¬ì‹œë„ ë¡œì§)
            max_retries = 3
            client = None
            
            for attempt in range(max_retries):
                try:
                    client = chromadb.PersistentClient(
                        path=chroma_path,
                        settings=chromadb.config.Settings(
                            allow_reset=True,
                            anonymized_telemetry=False
                        )
                    )
                    # session_stateì— í´ë¼ì´ì–¸íŠ¸ ì €ì¥
                    st.session_state.chroma_client = client
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"Client connection attempt {attempt + 1} failed: {e}")
                        time.sleep(1)
                    else:
                        raise e
            
            if client is None:
                raise Exception("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
            
            collection_name = "bizmob_documents"
            
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
            try:
                client.delete_collection(name=collection_name)
                logger.info("Existing collection deleted")
                time.sleep(0.5)  # ì ì‹œ ëŒ€ê¸°
            except:
                logger.info("No existing collection to delete")
            
            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            collection = client.create_collection(name=collection_name)
            logger.info("New collection created")
            
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (í…ìŠ¤íŠ¸ ì •ì œ)
            documents_texts = []
            documents_metadatas = []
            documents_ids = []
            
            for i, doc in enumerate(documents):
                # í…ìŠ¤íŠ¸ ì •ì œ (íŠ¹ìˆ˜ë¬¸ì ë° ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
                clean_text = doc.page_content.strip()
                if clean_text:
                    documents_texts.append(clean_text)
                    documents_metadatas.append(doc.metadata)
                    documents_ids.append(f"doc_{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            
            if not documents_texts:
                st.warning("ì €ì¥í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì„ë² ë”© ìƒì„±
            logger.info("Generating embeddings...")
            embeddings_list = embeddings.embed_documents(documents_texts)
            logger.info(f"Generated {len(embeddings_list)} embeddings")
            
            # ChromaDBì— ì €ì¥
            collection.add(
                documents=documents_texts,
                embeddings=embeddings_list,
                metadatas=documents_metadatas,
                ids=documents_ids
            )
            
            logger.info("ChromaDB document save completed")
            st.success(f"âœ… {len(documents_texts)}ê°œ ë¬¸ì„œê°€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ëœ ë¬¸ì„œ ìˆ˜ í™•ì¸
            try:
                count = collection.count()
                logger.info(f"Total documents in collection: {count}")
                st.info(f"ğŸ“Š í˜„ì¬ ë²¡í„° DBì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {count}ê°œ")
                
                # ì €ì¥ëœ ë¬¸ì„œ ìƒ˜í”Œ í™•ì¸
                if count > 0:
                    sample_results = collection.get(limit=1)
                    if sample_results['documents']:
                        sample_text = sample_results['documents'][0][:100]
                        logger.info(f"Sample document: {sample_text}...")
                        st.info(f"ğŸ“ ì €ì¥ëœ ë¬¸ì„œ ìƒ˜í”Œ: {sample_text}...")
                
            except Exception as e:
                logger.warning(f"Could not get collection count: {e}")
            
        except Exception as e:
            logger.error(f"ChromaDB save failed: {e}")
            st.error(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return
        
    except Exception as e:
        error_msg = f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}"
        logger.error(f"Vector database save failed: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")

def load_chroma_store():
    """ChromaDBì—ì„œ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (ê°•í™”ëœ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬)"""
    if not CHROMADB_AVAILABLE:
        error_msg = "ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        st.error(error_msg)
        return None
    
    try:
        logger.info("=== ChromaDB ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œì‘ ===")
        
        # ìºì‹œëœ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = get_embedding_model()
        if embeddings is None:
            logger.error("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        logger.info("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ê°•í™”ëœ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬)
        import chromadb
        from langchain_community.vectorstores import Chroma
        import time
        import gc
        
        chroma_path = get_chroma_db_path()
        logger.info(f"ChromaDB ê²½ë¡œ: {chroma_path}")
        
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(chroma_path):
            os.makedirs(chroma_path, exist_ok=True)
            logger.info(f"ChromaDB ë””ë ‰í† ë¦¬ ìƒì„±: {chroma_path}")
        
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ê³¼ ì„ë² ë”©ìœ¼ë¡œ ê³ ìœ  í‚¤ ìƒì„±
        selected_model = st.session_state.get('selected_model', 'exaone3.5')
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        global_vector_store_key = f"global_vector_store_{selected_model}_{selected_embedding}"
        logger.info(f"ë²¡í„° ìŠ¤í† ì–´ í‚¤: {global_vector_store_key}")
        
        # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if global_vector_store_key in st.session_state:
            try:
                logger.info("ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ìºì‹œ í™•ì¸ ì¤‘...")
                vector_store = st.session_state[global_vector_store_key]
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
                test_collection = vector_store._collection
                doc_count = test_collection.count()
                logger.info(f"ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì¬ì‚¬ìš© ì„±ê³µ - ë¬¸ì„œ ìˆ˜: {doc_count}")
                return vector_store
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì¬ì‚¬ìš© ì‹¤íŒ¨: {e}")
                # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì œê±°
                del st.session_state[global_vector_store_key]
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                time.sleep(1)
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        logger.info("ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
        try:
            client = chromadb.PersistentClient(
                path=chroma_path,
                settings=chromadb.config.Settings(
                    allow_reset=True,
                    anonymized_telemetry=False,
                    is_persistent=True,
                    persist_directory=chroma_path
                )
            )
            
            # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸
            client.heartbeat()
            logger.info("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            logger.warning(f"ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨, ì¬ì‹œë„: {e}")
            # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ í›„ ì¬ì‹œë„
            try:
                import psutil
                logger.info("ê¸°ì¡´ ChromaDB í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘...")
                for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                    try:
                        if 'chroma' in proc.info['name'].lower() or any('chroma' in str(cmd).lower() for cmd in proc.info['cmdline'] or []):
                            proc.terminate()
                            logger.info(f"ChromaDB í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: {proc.info['pid']}")
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        pass
                time.sleep(2)
                
                logger.info("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„± ì¤‘...")
                client = chromadb.PersistentClient(
                    path=chroma_path,
                    settings=chromadb.config.Settings(
                        allow_reset=True,
                        anonymized_telemetry=False,
                        is_persistent=True,
                        persist_directory=chroma_path
                    )
                )
                client.heartbeat()
                logger.info("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì¬ì—°ê²° ì„±ê³µ")
                
            except Exception as e2:
                logger.error(f"ChromaDB í´ë¼ì´ì–¸íŠ¸ ì¬ì—°ê²° ì‹¤íŒ¨: {e2}")
                return None
        
        collection_name = "bizmob_documents"
        logger.info(f"ì»¬ë ‰ì…˜ ì´ë¦„: {collection_name}")
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        try:
            collection = client.get_collection(name=collection_name)
            doc_count = collection.count()
            logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì„±ê³µ - ë¬¸ì„œ ìˆ˜: {doc_count}")
        except Exception as e:
            logger.info("ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±")
            collection = client.create_collection(name=collection_name)
            logger.info("ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
        
        # LangChain Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        logger.info("LangChain Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
        vector_store = Chroma(
            client=client,
            collection_name=collection_name,
            embedding_function=embeddings
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì „ì—­ì— ì €ì¥
        st.session_state[global_vector_store_key] = vector_store
        
        logger.info("=== ChromaDB ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ ===")
        return vector_store
        
    except Exception as e:
        error_msg = f"ChromaDB ë¡œë“œ ì‹¤íŒ¨: {e}"
        logger.error(f"ChromaDB ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
        st.error(f"âŒ {error_msg}")
        return None

############################### 2ë‹¨ê³„ : RAG ê¸°ëŠ¥ êµ¬í˜„ê³¼ ê´€ë ¨ëœ í•¨ìˆ˜ë“¤ ##########################

## í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ êµ¬í˜„
class HybridRetriever:
    """BM25ì™€ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""
    
    def __init__(self, vector_store, documents: List[Document], k: int = 8, 
                 bm25_weight: float = 0.3, vector_weight: float = 0.7):
        self.vector_store = vector_store
        self.documents = documents
        self.k = k
        
        # BM25 ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.bm25_retriever = BM25Retriever.from_documents(documents)
        self.bm25_retriever.k = k
        
        # ë²¡í„° ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.vector_retriever = vector_store.as_retriever(search_kwargs={"k": k})
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        # ì•™ìƒë¸” ê²€ìƒ‰ê¸° ìƒì„±
        self._create_ensemble_retriever()
    
    def _create_ensemble_retriever(self):
        """ì•™ìƒë¸” ê²€ìƒ‰ê¸° ìƒì„±"""
        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[self.bm25_retriever, self.vector_retriever],
            weights=[self.bm25_weight, self.vector_weight]
        )
    
    def update_weights(self, bm25_weight: float, vector_weight: float):
        """ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        self._create_ensemble_retriever()
        logger.info(f"ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
    
    def search(self, query: str, k: int = 3, 
               bm25_weight: float = None, vector_weight: float = None) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            logger.info(f"=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query[:50]}...' ===")
            
            # ì „ë‹¬ë°›ì€ ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
            if bm25_weight is not None and vector_weight is not None:
                self.update_weights(bm25_weight, vector_weight)
            
            logger.info(f"ê²€ìƒ‰ ê°€ì¤‘ì¹˜ - BM25: {self.bm25_weight:.2f}, ë²¡í„°: {self.vector_weight:.2f}")
            
            # 1ì°¨ ê²€ìƒ‰: k=8ê°œ ê²°ê³¼
            logger.info("1ì°¨ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... (BM25 + ë²¡í„° ì•™ìƒë¸”)")
            initial_results = self.ensemble_retriever.get_relevant_documents(query)
            logger.info(f"1ì°¨ ê²€ìƒ‰ ì™„ë£Œ: {len(initial_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ ë¡œê¹…
            for i, doc in enumerate(initial_results[:3]):  # ìƒìœ„ 3ê°œë§Œ ë¡œê¹…
                source = doc.metadata.get('source', 'Unknown')
                title = doc.metadata.get('title', 'No Title')
                logger.info(f"  ë¬¸ì„œ {i+1}: {source} | {title}")
            
            # 2ì°¨ ì¬ìˆœìœ„í™”: ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ë° ìƒìœ„ kê°œ ì„ íƒ
            logger.info("2ì°¨ ì¬ìˆœìœ„í™”(Reranking) ì‹¤í–‰ ì¤‘...")
            reranked_results = self._rerank_results(query, initial_results, k)
            
            logger.info(f"=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ ===")
            logger.info(f"  ì´ˆê¸° ê²°ê³¼: {len(initial_results)}ê°œ â†’ ìµœì¢… ê²°ê³¼: {len(reranked_results)}ê°œ")
            
            # ìµœì¢… ê²°ê³¼ ìƒì„¸ ë¡œê¹…
            for i, doc in enumerate(reranked_results):
                source = doc.metadata.get('source', 'Unknown')
                title = doc.metadata.get('title', 'No Title')
                relevance = doc.metadata.get('relevance_score', 'N/A')
                logger.info(f"  ìµœì¢… {i+1}ìœ„: {source} | {title} | ì ìˆ˜: {relevance}")
            
            return reranked_results
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©
            logger.info("ë²¡í„° ê²€ìƒ‰ í´ë°± ì‹¤í–‰...")
            try:
                logger.info("ChromaDB ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                vector_results = self.vector_retriever.get_relevant_documents(query)
                logger.info(f"ë²¡í„° ê²€ìƒ‰ í´ë°± ì™„ë£Œ: {len(vector_results)}ê°œ ë¬¸ì„œ")
                
                # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
                for i, doc in enumerate(vector_results[:3]):
                    source = doc.metadata.get('source', 'Unknown')
                    title = doc.metadata.get('title', 'No Title')
                    logger.info(f"  ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ {i+1}: {source} | {title}")
                
                return vector_results
            except Exception as vector_error:
                logger.error(f"ë²¡í„° ê²€ìƒ‰ í´ë°±ë„ ì‹¤íŒ¨: {vector_error}")
                return []
    
    def _rerank_results(self, query: str, documents: List[Document], k: int) -> List[Document]:
        """ê²€ìƒ‰ ê²°ê³¼ ì¬ìˆœìœ„í™”"""
        try:
            logger.info(f"ì¬ìˆœìœ„í™” ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
            scored_docs = []
            
            for i, doc in enumerate(documents):
                # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ + ë©”íƒ€ë°ì´í„° ê°€ì¤‘ì¹˜)
                score = self._calculate_relevance_score(query, doc)
                scored_docs.append((doc, score))
                
                # ìƒìœ„ 5ê°œ ë¬¸ì„œì˜ ì ìˆ˜ë§Œ ë¡œê¹…
                if i < 5:
                    source = doc.metadata.get('source', 'Unknown')
                    title = doc.metadata.get('title', 'No Title')
                    logger.info(f"  ë¬¸ì„œ {i+1} ì ìˆ˜: {score:.3f} | {source} | {title}")
            
            # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            scored_docs.sort(key=lambda x: x[1], reverse=True)
            logger.info(f"ì¬ìˆœìœ„í™” ì™„ë£Œ: ìƒìœ„ {k}ê°œ ë¬¸ì„œ ì„ íƒ")
            
            # ìƒìœ„ kê°œ ë°˜í™˜í•˜ê³  ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì €ì¥
            final_docs = []
            for doc, score in scored_docs[:k]:
                doc.metadata['relevance_score'] = round(score, 3)
                final_docs.append(doc)
            
            return final_docs
            
        except Exception as e:
            logger.warning(f"ì¬ìˆœìœ„í™” ì‹¤íŒ¨: {e}")
            return documents[:k]
    
    def _calculate_relevance_score(self, query: str, doc: Document) -> float:
        """ë¬¸ì„œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        score_details = []
        
        try:
            # 1. í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ (BM25 ìŠ¤íƒ€ì¼)
            query_words = set(query.lower().split())
            doc_words = set(doc.page_content.lower().split())
            
            # ê³µí†µ ë‹¨ì–´ ìˆ˜
            common_words = query_words.intersection(doc_words)
            if common_words:
                keyword_score = len(common_words) * 0.1
                score += keyword_score
                score_details.append(f"í‚¤ì›Œë“œ: +{keyword_score:.3f} ({len(common_words)}ê°œ ê³µí†µ)")
            
            # 2. ë©”íƒ€ë°ì´í„° ê°€ì¤‘ì¹˜
            metadata = doc.metadata
            if metadata:
                # ìµœì‹  ë¬¸ì„œ ìš°ì„ 
                if 'updated' in metadata:
                    try:
                        from datetime import datetime
                        updated_date = datetime.fromisoformat(metadata['updated'].replace('Z', '+00:00'))
                        days_old = (datetime.now().replace(tzinfo=updated_date.tzinfo) - updated_date).days
                        if days_old <= 30:  # 30ì¼ ì´ë‚´
                            score += 0.2
                            score_details.append("ìµœì‹ ì„±(30ì¼): +0.200")
                        elif days_old <= 90:  # 90ì¼ ì´ë‚´
                            score += 0.1
                            score_details.append("ìµœì‹ ì„±(90ì¼): +0.100")
                    except:
                        pass
                
                # ë¬¸ì„œ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜
                doctype_weights = {
                    'api': 0.3,
                    'spec': 0.3,
                    'guide': 0.2,
                    'blog': 0.1
                }
                
                if 'doctype' in metadata:
                    doc_type = metadata['doctype'].lower()
                    for dt, weight in doctype_weights.items():
                        if dt in doc_type:
                            score += weight
                            score_details.append(f"ë¬¸ì„œíƒ€ì…({dt}): +{weight:.3f}")
                            break
                
                # íŒŒì¼ í™•ì¥ìë³„ ê°€ì¤‘ì¹˜
                if 'source' in metadata:
                    source = metadata['source'].lower()
                    if source.endswith('.pdf'):
                        score += 0.1  # PDF ìš°ì„ 
                        score_details.append("íŒŒì¼í˜•ì‹(PDF): +0.100")
                    elif source.endswith(('.md', '.txt')):
                        score += 0.05
                        score_details.append("íŒŒì¼í˜•ì‹(TXT/MD): +0.050")
            
            # 3. ë‚´ìš© ê¸¸ì´ ê°€ì¤‘ì¹˜ (ì ë‹¹í•œ ê¸¸ì´ ìš°ì„ )
            content_length = len(doc.page_content)
            if 100 <= content_length <= 1000:
                score += 0.1
                score_details.append("ë‚´ìš©ê¸¸ì´(ì ë‹¹): +0.100")
            elif content_length > 1000:
                score += 0.05
                score_details.append("ë‚´ìš©ê¸¸ì´(ê¸´): +0.050")
            
            # ì ìˆ˜ ìƒì„¸ ì •ë³´ ë¡œê¹… (ë””ë²„ê·¸ìš©)
            if score_details:
                source = metadata.get('source', 'Unknown') if metadata else 'Unknown'
                title = metadata.get('title', 'No Title') if metadata else 'No Title'
                logger.debug(f"ì ìˆ˜ ê³„ì‚° ìƒì„¸ - {source} | {title}: {' + '.join(score_details)} = {score:.3f}")
            
        except Exception as e:
            logger.warning(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        
        return score

def get_hybrid_retriever(vector_store, k: int = 8, 
                        bm25_weight: float = None, vector_weight: float = None) -> HybridRetriever:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±"""
    try:
        logger.info("=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì‹œì‘ ===")
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ì „ë‹¬ë°›ì€ ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        if bm25_weight is None or vector_weight is None:
            config = get_hybrid_search_config()
            bm25_weight = config['bm25_weight']
            vector_weight = config['vector_weight']
            logger.info(f"ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‚¬ìš© - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
        else:
            logger.info(f"ì „ë‹¬ë°›ì€ ê°€ì¤‘ì¹˜ ì‚¬ìš© - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
        
        # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        all_docs = []
        try:
            logger.info("ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì¤‘...")
            # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
            collection = vector_store._collection
            logger.info(f"ChromaDB ì»¬ë ‰ì…˜ ì ‘ê·¼: {collection.name}")
            
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            total_count = collection.count()
            logger.info(f"ì»¬ë ‰ì…˜ ì´ ë¬¸ì„œ ìˆ˜: {total_count}")
            
            if total_count == 0:
                logger.warning("ì»¬ë ‰ì…˜ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
            results = collection.get(include=['documents', 'metadatas'])
            logger.info(f"ë¬¸ì„œ ì¡°íšŒ ê²°ê³¼: {len(results['documents'])}ê°œ ë¬¸ì„œ")
            
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ ë¡œê¹…
            if results['metadatas']:
                sample_metadata = results['metadatas'][0]
                logger.info(f"ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ: {sample_metadata}")
            
            for i, (doc_content, metadata) in enumerate(zip(results['documents'], results['metadatas'])):
                doc = Document(
                    page_content=doc_content,
                    metadata=metadata
                )
                all_docs.append(doc)
                
                # ì²˜ìŒ 3ê°œ ë¬¸ì„œì˜ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ë¡œê¹…
                if i < 3:
                    content_preview = doc_content[:100] + "..." if len(doc_content) > 100 else doc_content
                    source = metadata.get('source', 'Unknown')
                    title = metadata.get('title', 'No Title')
                    logger.info(f"ë¬¸ì„œ {i+1} ë¯¸ë¦¬ë³´ê¸°: {source} | {title} | ë‚´ìš©: {content_preview}")
                
        except Exception as e:
            logger.error(f"ChromaDB ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
            all_docs = []
        
        logger.info(f"ì´ {len(all_docs)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± (ê°€ì¤‘ì¹˜ í¬í•¨)
        logger.info("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ê°ì²´ ìƒì„± ì¤‘...")
        hybrid_retriever = HybridRetriever(
            vector_store, all_docs, k, 
            bm25_weight=bm25_weight, 
            vector_weight=vector_weight
        )
        logger.info(f"=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ: {len(all_docs)}ê°œ ë¬¸ì„œ, ê°€ì¤‘ì¹˜: BM25={bm25_weight:.2f}, Vector={vector_weight:.2f} ===")
        
        return hybrid_retriever
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        return None

# ì „ì—­ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ë³€ìˆ˜ ì¶”ê°€ (íŒŒì¼ ìƒë‹¨ì—)
HYBRID_SEARCH_CONFIG = {
    'bm25_weight': 0.3,
    'vector_weight': 0.7,
    'initial_k': 8,
    'final_k': 3,
    'enable_reranking': True,
    'metadata_boost': True,
    'recency_boost': True
}

def get_hybrid_search_config():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ë°˜í™˜"""
    global HYBRID_SEARCH_CONFIG
    
    # UIì—ì„œ ì„¤ì •í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ì‚¬ìš©
    if 'hybrid_search_config' in st.session_state:
        config = st.session_state.hybrid_search_config
        # ì „ì—­ ì„¤ì • ì—…ë°ì´íŠ¸
        HYBRID_SEARCH_CONFIG.update({
            'bm25_weight': config.get('bm25_weight', 0.3),
            'vector_weight': config.get('vector_weight', 0.7)
        })
        logger.info(f"ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ - BM25: {HYBRID_SEARCH_CONFIG['bm25_weight']:.2f}, Vector: {HYBRID_SEARCH_CONFIG['vector_weight']:.2f}")
    
    return HYBRID_SEARCH_CONFIG.copy()

def update_hybrid_search_config(config: dict):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ì—…ë°ì´íŠ¸"""
    global HYBRID_SEARCH_CONFIG
    
    try:
        # ì „ì—­ ì„¤ì • ì—…ë°ì´íŠ¸
        HYBRID_SEARCH_CONFIG.update({
            'bm25_weight': config['bm25_weight'],
            'vector_weight': config['vector_weight'],
            'initial_k': config.get('initial_k', 8),
            'final_k': config.get('final_k', 3),
            'enable_reranking': config.get('enable_reranking', True),
            'metadata_boost': config.get('metadata_boost', True),
            'recency_boost': config.get('recency_boost', True)
        })
        
        # ì„¸ì…˜ ìƒíƒœë„ ì—…ë°ì´íŠ¸
        if 'hybrid_search_config' not in st.session_state:
            st.session_state['hybrid_search_config'] = {}
        
        st.session_state['hybrid_search_config'].update({
            'bm25_weight': config['bm25_weight'],
            'vector_weight': config['vector_weight'],
            'initial_k': config.get('initial_k', 8),
            'final_k': config.get('final_k', 3),
            'enable_reranking': config.get('enable_reranking', True),
            'metadata_boost': config.get('metadata_boost', True),
            'recency_boost': config.get('recency_boost', True)
        })
        
        logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ - BM25: {config['bm25_weight']:.2f}, Vector: {config['vector_weight']:.2f}")
        return True
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_hybrid_search(query: str, vector_store, bm25_weight: float = None, vector_weight: float = None) -> dict:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ì¸¡ì •"""
    try:
        import time
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ì „ë‹¬ë°›ì€ ê°’ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì„¤ì • ì‚¬ìš©)
        if bm25_weight is None or vector_weight is None:
            config = get_hybrid_search_config()
            bm25_weight = config['bm25_weight']
            vector_weight = config['vector_weight']
            logger.info(f"í…ŒìŠ¤íŠ¸ì— í˜„ì¬ ì„¤ì •ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
        else:
            logger.info(f"í…ŒìŠ¤íŠ¸ì— ì „ë‹¬ë°›ì€ ê°€ì¤‘ì¹˜ ì‚¬ìš© - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
        
        # ë²¡í„° ê²€ìƒ‰ë§Œ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        vector_retriever = vector_store.as_retriever(search_kwargs={"k": 3})
        vector_results = vector_retriever.invoke(query)
        vector_time = time.time() - start_time
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ê°€ì¤‘ì¹˜ í¬í•¨)
        start_time = time.time()
        hybrid_retriever = get_hybrid_retriever(
            vector_store, k=8, 
            bm25_weight=bm25_weight, 
            vector_weight=vector_weight
        )
        hybrid_results = hybrid_retriever.search(
            query, k=3,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight
        )
        hybrid_time = time.time() - start_time
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        performance_metrics = {
            'search_time': round(hybrid_time, 3),
            'result_count': len(hybrid_results),
            'avg_relevance': 'N/A',  # ê´€ë ¨ì„± ì ìˆ˜ëŠ” ë©”íƒ€ë°ì´í„°ì— ì €ì¥ë˜ì–´ ìˆìŒ
            'bm25_weight': bm25_weight,
            'vector_weight': vector_weight
        }
        
        # ê²°ê³¼ì— ê´€ë ¨ì„± ì ìˆ˜ ì¶”ê°€ (ë©”íƒ€ë°ì´í„°ì— ì €ì¥ëœ ê²½ìš°)
        for doc in vector_results:
            if 'relevance_score' not in doc.metadata:
                doc.metadata['relevance_score'] = 'N/A'
        
        for doc in hybrid_results:
            if 'relevance_score' not in doc.metadata:
                doc.metadata['relevance_score'] = 'N/A'
        
        return {
            'vector_results': vector_results,
            'hybrid_results': hybrid_results,
            'performance_metrics': performance_metrics,
            'comparison': {
                'vector_time': round(vector_time, 3),
                'hybrid_time': round(hybrid_time, 3),
                'time_improvement': round((vector_time - hybrid_time) / vector_time * 100, 1) if vector_time > 0 else 0,
                'result_overlap': len(set([doc.metadata.get('file_name', '') for doc in vector_results]) & 
                                   set([doc.metadata.get('file_name', '') for doc in hybrid_results])),
                'weights_used': f"BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}"
            }
        }
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

## ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬
def process_question(user_question, rag_chain=None):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ë°˜í™˜"""
    logger.info(f"=== ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {user_question[:50]}... ===")
    try:
        # RAG ì²´ì¸ì´ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê°€ì ¸ì˜¤ê¸°
        if rag_chain is None:
            rag_chain = get_cached_rag_chain()
            if rag_chain is None:
                logger.error("RAG ì²´ì¸ ìƒì„± ì‹¤íŒ¨")
                st.error("RAG ì²´ì¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None, []
        
        # ì§ˆë¬¸ ì²˜ë¦¬
        logger.info("=== RAG ì²´ì¸ ì‹¤í–‰ ì‹œì‘ ===")
        response = rag_chain.invoke(user_question)
        logger.info(f"RAG ì²´ì¸ ì‹¤í–‰ ì™„ë£Œ, ì‘ë‹µ ê¸¸ì´: {len(response) if response else 0}")
        
        if response:
            logger.info(f"ìƒì„±ëœ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:200]}...")
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©)
        logger.info("=== ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘ ===")
        retrieve_docs = []
        try:
            logger.info("ë²¡í„° ìŠ¤í† ì–´ ê°€ì ¸ì˜¤ê¸° ì‹œì‘...")
            vector_store = get_cached_vector_store()
            if vector_store:
                logger.info("ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì‹œì‘...")
                
                # í˜„ì¬ ì„¤ì •ëœ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
                current_config = get_hybrid_search_config()
                bm25_weight = current_config['bm25_weight']
                vector_weight = current_config['vector_weight']
                logger.info(f"í˜„ì¬ ì„¤ì •ëœ ê°€ì¤‘ì¹˜ - BM25: {bm25_weight:.2f}, Vector: {vector_weight:.2f}")
                
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì‚¬ìš© (í˜„ì¬ ê°€ì¤‘ì¹˜ë¡œ ìƒì„±)
                hybrid_retriever = get_hybrid_retriever(
                    vector_store, k=8, 
                    bm25_weight=bm25_weight, 
                    vector_weight=vector_weight
                )
                if hybrid_retriever:
                    logger.info("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì„±ê³µ, ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                    # ê²€ìƒ‰ ì‹œì—ë„ í˜„ì¬ ê°€ì¤‘ì¹˜ ì „ë‹¬
                    retrieve_docs = hybrid_retriever.search(
                        user_question, k=3,
                        bm25_weight=bm25_weight,
                        vector_weight=vector_weight
                    )
                    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ, ë¬¸ì„œ ìˆ˜: {len(retrieve_docs)}")
                    
                    # ê²€ìƒ‰ëœ ë¬¸ì„œ ìƒì„¸ ì •ë³´ ë¡œê¹…
                    for i, doc in enumerate(retrieve_docs):
                        source = doc.metadata.get('source', 'Unknown')
                        title = doc.metadata.get('title', 'No Title')
                        relevance = doc.metadata.get('relevance_score', 'N/A')
                        logger.info(f"  ê²€ìƒ‰ëœ ë¬¸ì„œ {i+1}: {source} | {title} | ê´€ë ¨ì„±: {relevance}")
                else:
                    # í´ë°±: ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰
                    logger.info("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„± ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ í´ë°± ì‹¤í–‰...")
                    logger.info("ChromaDB ì§ì ‘ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
                    retrieve_docs = retriever.invoke(user_question)
                    logger.info(f"ë²¡í„° ê²€ìƒ‰ í´ë°± ì™„ë£Œ, ë¬¸ì„œ ìˆ˜: {len(retrieve_docs)}")
                    
                    # í´ë°± ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
                    for i, doc in enumerate(retrieve_docs):
                        source = doc.metadata.get('source', 'Unknown')
                        title = doc.metadata.get('title', 'No Title')
                        logger.info(f"  í´ë°± ê²€ìƒ‰ ë¬¸ì„œ {i+1}: {source} | {title}")
            else:
                logger.warning("ë²¡í„° ìŠ¤í† ì–´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)

        logger.info("=== ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ ===")
        logger.info(f"ìµœì¢… ê²°ê³¼: ì‘ë‹µ ê¸¸ì´ {len(response) if response else 0}ì, ë¬¸ì„œ {len(retrieve_docs)}ê°œ")
        return response, retrieve_docs
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, []

@st.cache_resource
def get_cached_vector_store():
    """ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ ë°˜í™˜ (ëª¨ë¸ë³„ ìºì‹œ)"""
    try:
        logger.info("=== ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ ì‹œì‘ ===")
        
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ê³¼ ì„ë² ë”© ëª¨ë¸ë¡œ ìºì‹œ í‚¤ ìƒì„±
        selected_model = st.session_state.get('selected_model', 'exaone3.5')
        selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
        
        cache_key = f"vector_store_{selected_model}_{selected_embedding}"
        logger.info(f"ìºì‹œ í‚¤: {cache_key}")
        
        # ê¸°ì¡´ ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if cache_key in st.session_state:
            try:
                logger.info("ê¸°ì¡´ ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ ì¤‘...")
                vector_store = st.session_state[cache_key]
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
                test_collection = vector_store._collection
                doc_count = test_collection.count()
                logger.info(f"ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ìºì‹œ ì¬ì‚¬ìš© ì„±ê³µ: {cache_key} (ë¬¸ì„œ ìˆ˜: {doc_count})")
                return vector_store
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ìºì‹œ ì¬ì‚¬ìš© ì‹¤íŒ¨: {e}")
                # ê¸°ì¡´ ìºì‹œ ì œê±°
                del st.session_state[cache_key]
                logger.info("ì‹¤íŒ¨í•œ ìºì‹œ ì œê±° ì™„ë£Œ")
        
        # ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        logger.info("ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œì‘...")
        vector_store = load_chroma_store()
        if vector_store:
            st.session_state[cache_key] = vector_store
            logger.info(f"ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìºì‹œ ìƒì„± ì™„ë£Œ: {cache_key}")
        else:
            logger.error("ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨")
        
        logger.info("=== ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ ì™„ë£Œ ===")
        return vector_store
        
    except Exception as e:
        logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return None

@st.cache_resource
def get_cached_rag_chain():
    """ìºì‹œëœ RAG ì²´ì¸ ë°˜í™˜ (ëª¨ë¸ë³„ ìºì‹œ)"""
    try:
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ë¡œ ìºì‹œ í‚¤ ìƒì„±
        selected_model = st.session_state.get('selected_model', 'exaone3.5')
        cache_key = f"rag_chain_{selected_model}"
        
        # ê¸°ì¡´ ìºì‹œëœ RAG ì²´ì¸ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if cache_key in st.session_state:
            logger.info(f"ê¸°ì¡´ RAG ì²´ì¸ ìºì‹œ ì¬ì‚¬ìš©: {cache_key}")
            return st.session_state[cache_key]
        
        # ìƒˆ RAG ì²´ì¸ ìƒì„±
        rag_chain = get_rag_chain()
        if rag_chain:
            st.session_state[cache_key] = rag_chain
            logger.info(f"ìƒˆ RAG ì²´ì¸ ìºì‹œ ìƒì„±: {cache_key}")
        
        return rag_chain
        
    except Exception as e:
        logger.error(f"RAG ì²´ì¸ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return None

def get_rag_chain() -> Runnable:
    """RAG ì²´ì¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„)"""
    try:
        # ì„ íƒëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        selected_model = st.session_state.get('selected_model', 'exaone3.5')
        
        # Ollama LLM ì´ˆê¸°í™”
        from langchain_ollama import OllamaLLM
        llm = OllamaLLM(
            model=selected_model,
            temperature=0.1,
            top_p=0.9,
            max_tokens=2048
        )
        
        # ìºì‹œëœ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = get_embedding_model()
        if embeddings is None:
            logger.error("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        # ìºì‹œëœ ë²¡í„° ìŠ¤í† ì–´ ì‚¬ìš©
        vector_store = get_cached_vector_store()
        if vector_store is None:
            logger.error("ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        from langchain_core.prompts import PromptTemplate
        template = """ë‹¹ì‹ ì€ bizMOB Platform ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ í•œê¸€ë¡œ í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        
        prompt = PromptTemplate(
            input_variables=["context", "question"],
            template=template
        )
        
        # RAG ì²´ì¸ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©)
        from langchain_core.runnables import RunnablePassthrough
        from langchain_core.output_parsers import StrOutputParser
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±
        hybrid_retriever = get_hybrid_retriever(vector_store, k=8)
        if hybrid_retriever:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸° (Runnable ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)
            from langchain_core.runnables import Runnable
            from typing import Any, List
            
            class HybridSearchRetriever(Runnable):
                def __init__(self, hybrid_retriever):
                    super().__init__()
                    self.hybrid_retriever = hybrid_retriever
                
                def invoke(self, input_data: Any, config: Any = None) -> List[Document]:
                    """Runnable ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„"""
                    if isinstance(input_data, str):
                        query = input_data
                    elif isinstance(input_data, dict) and 'question' in input_data:
                        query = input_data['question']
                    else:
                        query = str(input_data)
                    
                    return self.hybrid_retriever.search(query, k=3)
                
                def get_relevant_documents(self, query: str) -> List[Document]:
                    """ê¸°ì¡´ retriever ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±"""
                    return self.hybrid_retriever.search(query, k=3)
            
            search_retriever = HybridSearchRetriever(hybrid_retriever)
        else:
            # í´ë°±: ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰
            search_retriever = vector_store.as_retriever(search_kwargs={"k": 3})
        
        chain = (
            {"context": search_retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        return chain
        
    except Exception as e:
        logger.error(f"RAG ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        st.error(f"RAG ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

############################### 3ë‹¨ê³„ : ì‘ë‹µê²°ê³¼ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ë³´ë„ë¡ ë„ì™€ì£¼ëŠ” í•¨ìˆ˜ ##########################

@st.cache_data(show_spinner=False)
def convert_pdf_to_images(pdf_path: str, dpi: int = 250) -> List[str]:
    doc = fitz.open(pdf_path)  # ë¬¸ì„œ ì—´ê¸°
    image_paths = []
    
    # ì´ë¯¸ì§€ ì €ì¥ìš© í´ë” ìƒì„±
    output_folder = "PDF_ì´ë¯¸ì§€_bizmob"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for page_num in range(len(doc)):  # ê° í˜ì´ì§€ë¥¼ ìˆœíšŒ
        page = doc.load_page(page_num)  # í˜ì´ì§€ ë¡œë“œ

        zoom = dpi / 72  # 72ì´ ë””í´íŠ¸ DPI
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat) # type: ignore

        image_path = os.path.join(output_folder, f"page_{page_num + 1}.png")  # í˜ì´ì§€ ì´ë¯¸ì§€ ì €ì¥ page_1.png, page_2.png, etc.
        pix.save(image_path)  # PNG í˜•íƒœë¡œ ì €ì¥
        image_paths.append(image_path)  # ê²½ë¡œë¥¼ ì €ì¥
        
    return image_paths

def display_pdf_page(image_path: str, page_number: int) -> None:
    try:
        image_bytes = open(image_path, "rb").read()  # íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì¸ì‹
        st.image(image_bytes, caption=f"Page {page_number}", output_format="PNG", width=600)
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def natural_sort_key(s):
    return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]

def check_vector_db_exists():
    """ë²¡í„°DBê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    return os.path.exists(get_chroma_db_path())

def load_saved_model_info():
    """ì €ì¥ëœ ëª¨ë¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜´"""
    try:
        if os.path.exists('vector_db_model_info.json'):
            import json
            with open('vector_db_model_info.json', 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            return model_info
        return None
    except Exception as e:
        st.warning(f"âš ï¸ ì €ì¥ëœ ëª¨ë¸ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

def check_ollama_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ í™•ì¸"""
    try:
        import subprocess
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if result.returncode == 0:
            return True
        return False
    except:
        return False

def get_ollama_models():
    """Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
    try:
        import subprocess
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            models = []
            for line in lines[1:]:  # ì²« ë²ˆì§¸ ì¤„ì€ í—¤ë”ì´ë¯€ë¡œ ì œì™¸
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 2:
                        model_name = parts[0]
                        model_size = parts[1] if len(parts) > 1 else "Unknown"
                        models.append({
                            'name': model_name,
                            'size': model_size
                        })
            return models
        return []
    except Exception as e:
        st.error(f"Ollama ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return []

def get_available_embedding_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜"""
    return {
        'sentence-transformers/all-MiniLM-L6-v2': {
            'name': 'all-MiniLM-L6-v2',
            'description': 'ì˜ì–´ ì „ìš©, ë¹ ë¥´ê³  ê°€ë²¼ìš´ ëª¨ë¸',
            'language': 'English',
            'size': 'Small'
        },
        'jhgan/ko-sroberta-multitask': {
            'name': 'ko-sroberta-multitask',
            'description': 'í•œêµ­ì–´ ì „ìš©, ë‹¤ì¤‘ ì‘ì—… ëª¨ë¸',
            'language': 'Korean',
            'size': 'Medium'
        },
        'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': {
            'name': 'paraphrase-multilingual-MiniLM-L12-v2',
            'description': 'ë‹¤êµ­ì–´ ì§€ì›, ê· í˜•ì¡íŒ ì„±ëŠ¥',
            'language': 'Multilingual',
            'size': 'Medium'
        },
        'sentence-transformers/all-mpnet-base-v2': {
            'name': 'all-mpnet-base-v2',
            'description': 'ì˜ì–´ ì „ìš©, ê³ í’ˆì§ˆ ì„ë² ë”©',
            'language': 'English',
            'size': 'Large'
        },
        'intfloat/multilingual-e5-large': {
            'name': 'multilingual-e5-large',
            'description': 'ë‹¤êµ­ì–´ ì§€ì›, ê³ í’ˆì§ˆ ì„ë² ë”©',
            'language': 'Multilingual',
            'size': 'Large'
        }
    }

class SafeSentenceTransformerEmbeddings(Embeddings):
    """safetensorsë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ì•ˆì „í•œ ì„ë² ë”© í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str, device: str = 'cpu'):
        self.model_name = model_name
        self.device = device
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ (safetensors ì§ì ‘ ì‚¬ìš©)"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ safetensors ê°•ì œ ì‚¬ìš©
            import os
            os.environ['SAFETENSORS_FAST_GPU'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '0'
            os.environ['TORCH_WEIGHTS_ONLY'] = '1'
            os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
            os.environ['TRANSFORMERS_USE_SAFETENSORS'] = '1'
            os.environ['TORCH_WARN_ON_LOAD'] = '0'
            os.environ['TORCH_LOAD_WARN_ONLY'] = '0'
            os.environ['TRANSFORMERS_SAFE_SERIALIZATION'] = '1'
            os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'
            
            # transformersì™€ safetensorsë¥¼ ì§ì ‘ ì‚¬ìš©
            from transformers import AutoTokenizer, AutoModel
            import torch
            import safetensors
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                use_safetensors=True
            )
            
            # ëª¨ë¸ ë¡œë“œ (safetensors ê°•ì œ ì‚¬ìš©)
            self.model = AutoModel.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                use_safetensors=True,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True
            )
            
            self.model.to(self.device)
            self.model.eval()
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise e
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            embeddings = []
            for text in texts:
                # í† í¬ë‚˜ì´ì§•
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    max_length=512,
                    truncation=True,
                    padding=True
                )
                
                # GPUë¡œ ì´ë™
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # ì„ë² ë”© ìƒì„±
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    # ë§ˆì§€ë§‰ hidden stateì˜ í‰ê· ì„ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
                    embedding = outputs.last_hidden_state.mean(dim=1)
                    embeddings.append(embedding.cpu().numpy().flatten().tolist())
            
            return embeddings
            
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e
    
    def embed_query(self, text: str) -> List[float]:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©"""
        if self.model is None:
            self._load_model()
        
        try:
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                max_length=512,
                truncation=True,
                padding=True
            )
            
            # GPUë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì„ë² ë”© ìƒì„±
            with torch.no_grad():
                outputs = self.model(**inputs)
                # ë§ˆì§€ë§‰ hidden stateì˜ í‰ê· ì„ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
                embedding = outputs.last_hidden_state.mean(dim=1)
                return embedding.cpu().numpy().flatten().tolist()
                
        except Exception as e:
            st.error(f"ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {str(e)}")
            raise e

@st.cache_resource
def get_embedding_model():
    """ì„ íƒëœ ì„ë² ë”© ëª¨ë¸ì„ ë°˜í™˜ (safetensors ì§€ì›)"""
    selected_embedding = st.session_state.get('selected_embedding_model', 'jhgan/ko-sroberta-multitask')
    logger.info(f"=== ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹œì‘: {selected_embedding} ===")
    
    try:
        logger.info("1. SafeSentenceTransformerEmbeddings ì‹œë„")
        logger.info(f"ëª¨ë¸ ì´ë¦„: {selected_embedding}, ë””ë°”ì´ìŠ¤: cpu")
        
        # ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤ ì‚¬ìš©
        embeddings = SafeSentenceTransformerEmbeddings(
            model_name=selected_embedding,
            device='cpu'
        )
        logger.info("SafeSentenceTransformerEmbeddings ë¡œë“œ ì„±ê³µ")
        logger.info(f"=== ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {selected_embedding} ===")
        return embeddings
        
    except Exception as e:
        logger.warning(f"SafeSentenceTransformerEmbeddings ì‹¤íŒ¨: {str(e)}")
        logger.info("HuggingFaceEmbeddingsë¡œ í´ë°± ì‹œë„...")
        st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        st.info("HuggingFaceEmbeddingsë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        
        try:
            logger.info("2. HuggingFaceEmbeddings ì¬ì‹œë„")
            logger.info(f"ëª¨ë¸ ì„¤ì •: device=cpu, torch_dtype=auto, low_cpu_mem_usage=True")
            
            # HuggingFaceEmbeddingsë¡œ fallback (safetensors ì‚¬ìš©)
            embeddings = HuggingFaceEmbeddings(
                model_name=selected_embedding,
                model_kwargs={
                    'device': 'cpu',
                    'torch_dtype': 'auto',
                    'low_cpu_mem_usage': True,
                    'trust_remote_code': True
                },
                encode_kwargs={'normalize_embeddings': True}
            )
            
            logger.info("HuggingFaceEmbeddings ë¡œë“œ ì„±ê³µ")
            logger.info(f"=== ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í´ë°±): {selected_embedding} ===")
            st.success(f"âœ… {selected_embedding} ëª¨ë¸ì„ HuggingFaceEmbeddingsë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return embeddings
            
        except Exception as e2:
            logger.error(f"HuggingFaceEmbeddings ì¬ì‹œë„ë„ ì‹¤íŒ¨: {str(e2)}", exc_info=True)
            st.error(f"HuggingFaceEmbeddings ì¬ì‹œë„ë„ ì‹¤íŒ¨: {str(e2)}")
            st.error("ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return None

def get_recommended_embedding_model(ai_model_name: str) -> str:
    """AI ëª¨ë¸ì— ë”°ë¥¸ ê¶Œì¥ ì„ë² ë”© ëª¨ë¸ì„ ë°˜í™˜"""
    model_mapping = {
        'exaone3.5': 'jhgan/ko-sroberta-multitask',
        'llama3': 'sentence-transformers/all-mpnet-base-v2',
        'llama3.2': 'sentence-transformers/all-mpnet-base-v2',
        'llama3.2:3b': 'sentence-transformers/all-MiniLM-L6-v2',
        'llama3.2:8b': 'sentence-transformers/all-mpnet-base-v2',
        'llama3.2:70b': 'intfloat/multilingual-e5-large',
        'mistral': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'mistral:7b': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'mistral:instruct': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'codellama': 'sentence-transformers/all-mpnet-base-v2',
        'codellama:7b': 'sentence-transformers/all-MiniLM-L6-v2',
        'codellama:13b': 'sentence-transformers/all-mpnet-base-v2',
        'codellama:34b': 'intfloat/multilingual-e5-large',
        'gemma': 'sentence-transformers/all-mpnet-base-v2',
        'gemma:2b': 'sentence-transformers/all-MiniLM-L6-v2',
        'gemma:7b': 'sentence-transformers/all-mpnet-base-v2',
        'qwen': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'qwen:7b': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'qwen:14b': 'intfloat/multilingual-e5-large',
        'phi': 'sentence-transformers/all-mpnet-base-v2',
        'phi:2.7b': 'sentence-transformers/all-MiniLM-L6-v2',
        'phi:3.5': 'sentence-transformers/all-mpnet-base-v2',
    }
    # ì •í™• ë§¤ì¹­
    if ai_model_name in model_mapping:
        return model_mapping[ai_model_name]
    # ë¶€ë¶„ ë§¤ì¹­
    for key, value in model_mapping.items():
        if key in ai_model_name.lower():
            return value
    return 'jhgan/ko-sroberta-multitask'

def get_chroma_db_path():
    """ChromaDB ê²½ë¡œ ë°˜í™˜"""
    chroma_path = "./chroma_db"
    logger.info(f"ChromaDB ê²½ë¡œ ì„¤ì •: {chroma_path}")
    return chroma_path

def get_model_info_path():
    """ëª¨ë¸ ì •ë³´ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    ai_model = st.session_state.get('selected_model', 'exaone3.5')
    import re
    safe_model = re.sub(r'[^a-zA-Z0-9_\-]', '_', ai_model)
    return f"vector_db_model_info_{safe_model}.json" 

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (íŒŒì¼ ê´€ë¦¬ ì „ìš©)"""
    logger.info("=== bizMOB íŒŒì¼ ê´€ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ===")
    
    st.set_page_config(
        page_title="bizMOB íŒŒì¼ ê´€ë¦¬",
        page_icon="ğŸ“",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    logger.info("í˜ì´ì§€ ì„¤ì • ì™„ë£Œ")

    # ì‚¬ì´ë“œë°” - AI ëª¨ë¸ ì„ íƒ
    logger.info("AI ëª¨ë¸ ì„ íƒ ì‹œì‘")
    if check_ollama_models():
        st.sidebar.success("âœ… Ollama ì—°ê²°ë¨")
        logger.info("Ollama ì—°ê²° ì„±ê³µ")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        available_models = get_ollama_models()
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆ˜: {len(available_models) if available_models else 0}")
        
        # ëª¨ë¸ ì„ íƒê¸° í‘œì‹œ
        show_model_selector(available_models, get_recommended_embedding_model, load_saved_model_info)
        logger.info("ëª¨ë¸ ì„ íƒê¸° í‘œì‹œ ì™„ë£Œ")
        
    else:
        st.sidebar.error("âŒ Ollama ì—°ê²° ì‹¤íŒ¨")
        st.sidebar.info("Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        logger.warning("Ollama ì—°ê²° ì‹¤íŒ¨")
    
    # ì‚¬ì´ë“œë°” - ì„ë² ë”© ëª¨ë¸ ì •ë³´
    logger.info("ì„ë² ë”© ëª¨ë¸ ì •ë³´ í‘œì‹œ ì‹œì‘")
    show_embedding_model_info(get_available_embedding_models, load_saved_model_info, get_recommended_embedding_model)
    logger.info("ì„ë² ë”© ëª¨ë¸ ì •ë³´ í‘œì‹œ ì™„ë£Œ")
    
    # ì±„íŒ… í˜ì´ì§€ ë§í¬
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ’¬ ì±„íŒ… í˜ì´ì§€")
    st.sidebar.markdown("[ì±„íŒ… í˜ì´ì§€ë¡œ ì´ë™](/Chat)")
    logger.info("ì±„íŒ… í˜ì´ì§€ ë§í¬ ì¶”ê°€ ì™„ë£Œ")
    
    # ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ (ì±„íŒ… ê¸°ëŠ¥ ì œì™¸)
    logger.info("ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ ì‹œì‘")
    show_admin_interface(
        None,  # display_chat_messages (Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ë¹„í™œì„±í™”)
        check_vector_db_exists, 
        initialize_vector_db_with_documents,
        None,  # add_chat_message (Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ë¹„í™œì„±í™”)
        None,  # process_question (Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ë¹„í™œì„±í™”)
        manage_uploaded_files, 
        load_saved_model_info
    )
    logger.info("ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ ì™„ë£Œ")
    
    logger.info("=== bizMOB íŒŒì¼ ê´€ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œë“œ ì™„ë£Œ ===")

if __name__ == "__main__":
    main() 